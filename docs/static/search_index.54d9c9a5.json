[{"id":0,"title":"SCTP Library API Reference","content":"#\n\n\nIntroduction#\n\nThe Simple Compact Transaction Protocol (SCTP) library provides a highly\nefficient and straightforward binary serialization format, based on the\nLIP-0006. It is designed for performance and ease of use, especially in\nresource-constrained environments like WebAssembly.\n\nThe library allows you to encode a sequence of typed data fields into a compact\nbyte stream and then decode that stream back into its original data structures.\nIt is written in C and exposes a simple, clean API for both encoding and\ndecoding operations.\n\n\nCore Concepts#\n\n\nEncoding Model#\n\nThe encoder uses a global singleton design. You initialize it once, add all your\ndata fields sequentially, and then retrieve the final byte buffer. This model\nsimplifies the process of creating a data stream, as you do not need to manage\nencoder instances.\n\n\nDecoding Models#\n\nThe library offers two distinct models for decoding a byte stream, allowing you\nto choose the best fit for your application's architecture.\n\n 1. Stateful Iteration (Pull-style): This is an instance-based approach where\n    you create a decoder for a specific data buffer. You then call\n    sctp_decoder_next() in a loop to \"pull\" data fields one by one. After each\n    call, the decoder instance is updated with the type, value, and size of the\n    decoded field. This model gives the caller full control over the decoding\n    loop.\n\n 2. Callback-Based (Push-style): This model is ideal for WebAssembly or\n    event-driven systems. You provide a handler function, and the decoder parses\n    the entire stream, \"pushing\" each decoded field to your callback as it's\n    found. This is driven by a single call to sctp_decoder_run().\n\n\nWire Format#\n\nSCTP uses a well-defined binary format where each data field is prefixed with a\n1-byte header that specifies its type and metadata. All multi-byte integers and\nfloats are encoded in little-endian byte order. For complete details on the\nbinary layout, see the SCTP Encoding Specification.\n\n--------------------------------------------------------------------------------\n\n\nGetting Started: A Complete Example#\n\nThis example demonstrates the full lifecycle of encoding data and then decoding\nit using the Stateful Iteration model.\n\n\n\n--------------------------------------------------------------------------------\n\n\nPublic Data Types#\n\nThese are the core data structures you will interact with when using the SCTP\nlibrary.\n\n\nsctp_type_t#\n\nAn enum that defines all possible data types in an SCTP stream.\n\n\n\n\nsctp_value_t#\n\nA union that holds the value of a decoded field. You must access the correct\nmember based on the field's sctp_type_t.\n\n\n\n\nsctp_decoder_t#\n\nA struct that holds the complete state of a decoder instance. When using the\nstateful iteration model, you will primarily access its public fields to get\ninformation about the last decoded item.\n\n\n\n--------------------------------------------------------------------------------\n\n\nUsage in WebAssembly#\n\nThe library is designed to integrate seamlessly with WebAssembly hosts. The\nprimary integration point is the callback-based decoder.\n\n\nCompiler Defines#\n\nWhen compiling the library for a Wasm environment that uses the callback model,\nyou must define SCTP_HANDLER_PROVIDED.\n\n * SCTP_HANDLER_PROVIDED: This preprocessor macro signals that the host\n   environment (e.g., JavaScript) will provide the implementation for the data\n   handler callback. This prevents the default (dummy) implementation from being\n   compiled.\n\n\nThe Data Handler Callback#\n\nThe host environment must implement and export a function with the following\nsignature. The SCTP decoder will call this function for every data field it\nsuccessfully parses from the stream.\n\n\n\n--------------------------------------------------------------------------------\n\n\nEncoder API Reference#\n\nThe encoder operates on a global internal state.\n\n\nsctp_encoder_init#\n\nInitializes or resets the global encoder with a new buffer of a specified\ncapacity.\n\n\n\n * capacity: The total size in bytes to allocate for the encoding buffer.\n\n\nsctp_encoder_data#\n\nGets a read-only pointer to the start of the encoded data buffer.\n\n\n\n * Returns: A const pointer to the byte buffer.\n\n\nsctp_encoder_size#\n\nGets the current size (number of bytes written) of the encoded data.\n\n\n\n * Returns: The number of bytes currently used in the buffer.\n\n\nsctp_encoder_add_* Functions#\n\nThese functions append data of a specific type to the stream.\n\nFUNCTION SIGNATURE                          DESCRIPTION\nvoid sctp_encoder_add_int8(int8_t v)        Appends an 8-bit signed integer.\nvoid sctp_encoder_add_uint8(uint8_t v)      Appends an 8-bit unsigned integer.\nvoid sctp_encoder_add_int16(int16_t v)      Appends a 16-bit signed integer.\nvoid sctp_encoder_add_uint16(uint16_t v)    Appends a 16-bit unsigned integer.\nvoid sctp_encoder_add_int32(int32_t v)      Appends a 32-bit signed integer.\nvoid sctp_encoder_add_uint32(uint32_t v)    Appends a 32-bit unsigned integer.\nvoid sctp_encoder_add_int64(int64_t v)      Appends a 64-bit signed integer.\nvoid sctp_encoder_add_uint64(uint64_t v)    Appends a 64-bit unsigned integer.\nvoid sctp_encoder_add_uleb128(uint64_t v)   Appends a ULEB128-encoded integer.\nvoid sctp_encoder_add_sleb128(int64_t v)    Appends an SLEB128-encoded integer.\nvoid sctp_encoder_add_float32(float v)      Appends a 32-bit float.\nvoid sctp_encoder_add_float64(double v)     Appends a 64-bit float (double).\nvoid sctp_encoder_add_eof(void)             Appends an End-Of-File marker.\n\n\nsctp_encoder_add_short#\n\nAppends a small integer (0-15) to the stream, encoded in a single byte.\n\n\n\n * value: The integer to encode. Must be <= 15.\n\n\nsctp_encoder_add_vector#\n\nAppends a variable-length byte array to the stream.\n\n\n\n * length: The size of the vector in bytes.\n * Returns: A writable pointer to the allocated space in the buffer. The caller\n   is responsible for writing length bytes to this location (e.g., using\n   memcpy).\n\nExample:\n\n\n\n--------------------------------------------------------------------------------\n\n\nDecoder API Reference#\n\n\nInitialization and Cleanup#\n\nsctp_decoder_from_buffer#\n\nCreates a new decoder instance that reads from an existing, externally managed\nbuffer.\n\n\n\n * buffer: A pointer to the data buffer to decode.\n * size: The size of the buffer in bytes.\n * Returns: A pointer to a new sctp_decoder_t instance, or NULL on failure.\n\nsctp_decoder_init#\n\nCreates a new decoder instance and allocates a writable data buffer within the\nWasm module's memory. This is primarily for hosts that need to write data into\nthe module before decoding.\n\n\n\n * size: The size of the data buffer to allocate.\n * Returns: A pointer to a new sctp_decoder_t instance, or NULL on failure.\n\nsctp_decoder_free#\n\nFrees a decoder instance created by sctp_decoder_from_buffer or\nsctp_decoder_init.\n\n\n\n * dec: The decoder instance to free.\n\n\nDecoding Methods#\n\nStateful Iteration#\n\nThis model uses sctp_decoder_next to read one field at a time.\n\nsctp_decoder_next#\n\nDecodes the next field from the stream and updates the decoder instance's\nlast_type, last_value, and last_size fields.\n\n\n\n * dec: The decoder instance.\n * Returns: The sctp_type_t of the decoded field, or SCTP_TYPE_EOF when the end\n   of the stream is reached.\n\nExample:\n\n\n\nCallback-Based#\n\nThis model uses sctp_decoder_run to parse the entire stream and invoke a\ncallback for each field.\n\nsctp_decoder_run#\n\nRuns the decoder over the entire buffer, invoking the host-provided\n__sctp_data_handler for each field.\n\n\n\n * dec: The decoder instance.\n * Returns: 0 on success, non-zero on error.\n\nExample (Host-side C code):\n\n","routePath":"/development/generated/sctp","lang":"","toc":[{"text":"Introduction","id":"introduction","depth":2,"charIndex":3},{"text":"Core Concepts","id":"core-concepts","depth":2,"charIndex":544},{"text":"Encoding Model","id":"encoding-model","depth":3,"charIndex":561},{"text":"Decoding Models","id":"decoding-models","depth":3,"charIndex":837},{"text":"Wire Format","id":"wire-format","depth":3,"charIndex":1687},{"text":"Getting Started: A Complete Example","id":"getting-started-a-complete-example","depth":2,"charIndex":2073},{"text":"Public Data Types","id":"public-data-types","depth":2,"charIndex":2316},{"text":"`sctp_type_t`","id":"sctp_type_t","depth":3,"charIndex":-1},{"text":"`sctp_value_t`","id":"sctp_value_t","depth":3,"charIndex":-1},{"text":"`sctp_decoder_t`","id":"sctp_decoder_t","depth":3,"charIndex":-1},{"text":"Usage in WebAssembly","id":"usage-in-webassembly","depth":2,"charIndex":2942},{"text":"Compiler Defines","id":"compiler-defines","depth":3,"charIndex":3100},{"text":"The Data Handler Callback","id":"the-data-handler-callback","depth":3,"charIndex":3486},{"text":"Encoder API Reference","id":"encoder-api-reference","depth":2,"charIndex":3790},{"text":"`sctp_encoder_init`","id":"sctp_encoder_init","depth":3,"charIndex":-1},{"text":"`sctp_encoder_data`","id":"sctp_encoder_data","depth":3,"charIndex":-1},{"text":"`sctp_encoder_size`","id":"sctp_encoder_size","depth":3,"charIndex":-1},{"text":"`sctp_encoder_add_*` Functions","id":"sctp_encoder_add_-functions","depth":3,"charIndex":-1},{"text":"`sctp_encoder_add_short`","id":"sctp_encoder_add_short","depth":3,"charIndex":-1},{"text":"`sctp_encoder_add_vector`","id":"sctp_encoder_add_vector","depth":3,"charIndex":-1},{"text":"Decoder API Reference","id":"decoder-api-reference","depth":2,"charIndex":6034},{"text":"Initialization and Cleanup","id":"initialization-and-cleanup","depth":3,"charIndex":6059},{"text":"`sctp_decoder_from_buffer`","id":"sctp_decoder_from_buffer","depth":4,"charIndex":-1},{"text":"`sctp_decoder_init`","id":"sctp_decoder_init","depth":4,"charIndex":-1},{"text":"`sctp_decoder_free`","id":"sctp_decoder_free","depth":4,"charIndex":-1},{"text":"Decoding Methods","id":"decoding-methods","depth":3,"charIndex":6857},{"text":"Stateful Iteration","id":"stateful-iteration","depth":4,"charIndex":6876},{"text":"Callback-Based","id":"callback-based","depth":4,"charIndex":7255}],"domain":"","frontmatter":{"title":"SCTP Library API Reference"},"version":""},{"id":1,"title":"Lea Standard Library (`stdlea`)","content":"Lea Standard Library (stdlea)#\n\nThe official standard library for developing secure and high-performance smart\ncontracts on the Lea platform. It provides a minimal, WASM-first set of C\nfunctions and macros, designed to be lightweight, efficient, and secure by\ndefault.\n\nstdlea replaces the standard C library with a custom implementation tailored for\nthe WebAssembly environment, focusing on memory safety and performance.\n\n\nFeatures#\n\n * WASM Integration: Macros (LEA_EXPORT, LEA_IMPORT) for seamless interaction\n   with the host environment.\n * Memory Management: A simple and efficient bump allocator (malloc,\n   allocator_reset). free() is disabled to prevent memory management errors.\n * Memory Safety: Functions like memset, memcpy, and memmove for safe memory\n   manipulation.\n * String Handling: A core set of string functions (strlen, strcmp, strcpy,\n   etc.).\n * Optional Formatting: Opt-in string formatting (printf, snprintf) and logging\n   (lea_log) that can be enabled for development and disabled for production to\n   reduce binary size.\n * Security Hardening: An optional Undefined Behavior Sanitizer (UBSan) to catch\n   common programming errors at runtime.\n * Simplified Build System: A stdlea.mk file that can be included in your\n   project's Makefile to handle all compiler flags and dependencies\n   automatically.\n\n\nGetting Started: Integrating stdlea#\n\nTo use stdlea in your project, you include the stdlea.mk file in your makefile.\nThis handles all the necessary compiler flags and source file includes.\n\n\nExample Makefile for a Smart Contract#\n\nHere is an example of a makefile for a simple ed25519.wasm smart contract that\nuses stdlea:\n\n\n\n\nBuild Configuration (stdlea.mk)#\n\nThe stdlea.mk file provides several variables to control the build:\n\nVARIABLE         DESCRIPTION                                                    DEFAULT\nENABLE_LEA_LOG   Enables the lea_log() function for printing messages to the    0\n                 host.\nENABLE_LEA_FMT   Enables the printf() and snprintf() functions for string       0\n                 formatting.\nENABLE_UBSEN     Enables the Undefined Behavior Sanitizer (UBSan) for runtime   0\n                 checks. This increases binary size and impacts performance.\n\n\nAPI Reference#\n\n\nstdlea.h#\n\nCore macros and functions for interacting with the Lea environment.\n\nFUNCTION/MACRO                      DESCRIPTION\nLEA_EXPORT(FUNC_NAME)               Exports a function from the Wasm module, making it callable\n                                    by the host.\nLEA_IMPORT(PROGRAM_ID, FUNC_NAME)   Imports a function from another module, allowing\n                                    cross-contract calls.\nLEA_ABORT()                         Immediately aborts execution and traps. Used for\n                                    unrecoverable errors.\nLEA_LOG(const char *msg)            Logs a message to the host. Only available if ENABLE_LEA_LOG\n                                    is 1.\nallocator_reset()                   Resets the heap bump allocator, clearing all previously\n                                    allocated memory.\nLEA_HEAP_SIZE                       Defines the total size of the static heap (default: 1 MiB).\n\n\nstdlib.h#\n\nMemory allocation and standard utilities.\n\nFUNCTION/MACRO              DESCRIPTION\nvoid *malloc(size_t size)   Allocates size bytes from the heap using a bump allocator.\nabort()                     Aborts program execution by causing a trap.\nfree(void *p)               Not available. stdlea uses a bump allocator. Calling free()\n                            will intentionally cause a compile-time error. Use\n                            allocator_reset() instead.\n\n\nstring.h#\n\nFunctions for memory and string manipulation.\n\nFUNCTION                                                 DESCRIPTION\nvoid *memset(void *dest, int val, size_t len)            Fills a block of memory with a value.\nvoid *memcpy(void *dest, const void *src, size_t len)    Copies a block of memory. Does not handle overlapping\n                                                         memory.\nvoid *memmove(void *dest, const void *src, size_t len)   Copies a block of memory. Handles overlapping memory\n                                                         correctly.\nint memcmp(const void *s1, const void *s2, size_t n)     Compares two blocks of memory.\nsize_t strlen(const char *s)                             Calculates the length of a null-terminated string.\nint strcmp(const char *s1, const char *s2)               Compares two null-terminated strings.\nint strncmp(const char *s1, const char *s2, size_t n)    Compares up to n characters of two strings.\nchar *strcpy(char *dest, const char *src)                Copies a null-terminated string.\nsize_t strnlen(const char *s, size_t maxlen)             Calculates the length of a string up to a maximum size.\n\n\nstdio.h#\n\nFormatted output functions. These are only available if ENABLE_LEA_FMT is set to\n1.\n\nFUNCTION                                                     DESCRIPTION\nprintf(const char *fmt, ...)                                 Prints a formatted string to the host environment.\nsnprintf(char *buf, size_t size, const char *fmt, ...)       Writes a formatted string to a buffer. See format specifiers\n                                                             below.\nvsnprintf(char *buf, size_t size, const char *fmt, va_list   Core implementation of snprintf that uses a va_list.\nargs)\n\nFormat Specifiers#\n\nThe printf and snprintf functions in stdlea support a subset of the standard C\nspecifiers, plus some custom additions designed for smart contract development.\n\nStandard Specifiers\n\nSPECIFIER   OUTPUT\n%d, %i      Signed decimal integer.\n%u          Unsigned decimal integer.\n%x          Unsigned hexadecimal integer (lowercase).\n%b          Unsigned binary integer (custom extension).\n%s          Null-terminated string. A NULL pointer is printed as (null).\n%c          Single character.\n%%          A literal % character.\n\nLength Modifiers\n\nMODIFIER   TYPE\nh          short or unsigned short\nhh         signed char or unsigned char\nll         long long or unsigned long long\n\nArbitrary-Length Specifiers (Custom)\n\nThese non-standard specifiers are powerful tools for handling raw data. Each\nconsumes two arguments from the stack: a size_t length, followed by a pointer.\n\nSPECIFIER   DESCRIPTION                                                  ARGUMENTS\n%*x         Hex blob                                                     (size_t, const unsigned char*)\n%*b         Binary blob                                                  (size_t, const unsigned char*)\n%*s         Sized string (can be used for non-null-terminated strings)   (size_t, const char*)\n\nExamples#\n\n1. Basic Formatting\n\n\n\n2. Hex and Binary Formatting\n\nThe custom %b specifier is useful for viewing flags or raw binary data.\n\n\n\n3. Arbitrary-Length Hex Blob\n\nThe %*x specifier is ideal for printing transaction hashes, public keys, or\nother fixed-size byte arrays.\n\n\n\n\nAuthor#\n\nDeveloped by Allwin Ketnawang.\n\n\nLicense#\n\nThis project is licensed under the MIT License. See the LICENSE file for\ndetails.","routePath":"/development/generated/stdlea","lang":"","toc":[{"text":"Features","id":"features","depth":2,"charIndex":424},{"text":"Getting Started: Integrating `stdlea`","id":"getting-started-integrating-stdlea","depth":2,"charIndex":-1},{"text":"Example Makefile for a Smart Contract","id":"example-makefile-for-a-smart-contract","depth":3,"charIndex":1528},{"text":"Build Configuration (`stdlea.mk`)","id":"build-configuration-stdleamk","depth":2,"charIndex":-1},{"text":"API Reference","id":"api-reference","depth":2,"charIndex":2232},{"text":"`stdlea.h`","id":"stdleah","depth":3,"charIndex":-1},{"text":"`stdlib.h`","id":"stdlibh","depth":3,"charIndex":-1},{"text":"`string.h`","id":"stringh","depth":3,"charIndex":-1},{"text":"`stdio.h`","id":"stdioh","depth":3,"charIndex":-1},{"text":"Format Specifiers","id":"format-specifiers","depth":4,"charIndex":5432},{"text":"Examples","id":"examples","depth":4,"charIndex":6710},{"text":"Author","id":"author","depth":2,"charIndex":6989},{"text":"License","id":"license","depth":2,"charIndex":7031}],"domain":"","frontmatter":{"title":"Lea Standard Library (`stdlea`)"},"version":""},{"id":2,"title":"Development","content":"#\n\nLearn about the Node API, Smart Contract Development, and the SDK.","routePath":"/development/","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":3,"title":"Markdown & MDX","content":"#\n\nRspress supports not only Markdown but also MDX, a powerful way to develop\ncontent.\n\n\nMarkdown#\n\nMDX is a superset of Markdown, which means you can write Markdown files as\nusual. For example:\n\n\n\n\nUse component#\n\nWhen you want to use React components in Markdown files, you should name your\nfiles with .mdx extension. For example:\n\n\n\n\nFront matter#\n\nYou can add Front Matter at the beginning of your Markdown file, which is a\nYAML-formatted object that defines some metadata. For example:\n\n\n\n> Note: By default, Rspress uses h1 headings as html headings.\n\nYou can also access properties defined in Front Matter in the body, for example:\n\n\n\nThe previously defined properties will be passed to the component as frontmatter\nproperties. So the final output will be:\n\n\n\n\nCustom container#\n\nYou can use the ::: syntax to create custom containers and support custom\ntitles. For example:\n\nInput:\n\n\n\nOutput:\n\nTIP\n\nThis is a block of type tip\n\nINFO\n\nThis is a block of type info\n\nWARNING\n\nThis is a block of type warning\n\nDANGER\n\nThis is a block of type danger\n\nDETAILS\n\nThis is a block of type details\n\nCustom Title\n\nThis is a block of Custom Title\n\nCustom Title\n\nThis is a block of Custom Title\n\n\nCode block#\n\n\nBasic usage#\n\nYou can use the ``` syntax to create code blocks and support custom titles. For\nexample:\n\nInput:\n\n\n\nOutput:\n\n\n\n\n\n\nShow line numbers#\n\nIf you want to display line numbers, you can enable the showLineNumbers option\nin the config file:\n\n\n\n\nWrap code#\n\nIf you want to wrap long code line by default, you can enable the\ndefaultWrapCode option in the config file:\n\n\n\n\nLine highlighting#\n\nYou can also apply line highlighting and code block title at the same time, for\nexample:\n\nInput:\n\n\n\nOutput:\n\n\n\n\nRustify MDX compiler#\n\nYou can enable Rustify MDX compiler by following config:","routePath":"/guide/","lang":"","toc":[{"text":"Markdown","id":"markdown","depth":2,"charIndex":88},{"text":"Use component","id":"use-component","depth":2,"charIndex":198},{"text":"Front matter","id":"front-matter","depth":2,"charIndex":336},{"text":"Custom container","id":"custom-container","depth":2,"charIndex":767},{"text":"Code block","id":"code-block","depth":2,"charIndex":1190},{"text":"Basic usage","id":"basic-usage","depth":3,"charIndex":1204},{"text":"Show line numbers","id":"show-line-numbers","depth":3,"charIndex":1332},{"text":"Wrap code","id":"wrap-code","depth":3,"charIndex":1455},{"text":"Line highlighting","id":"line-highlighting","depth":3,"charIndex":1580},{"text":"Rustify MDX compiler","id":"rustify-mdx-compiler","depth":2,"charIndex":1712}],"domain":"","frontmatter":{},"version":""},{"id":4,"title":"Hello world!","content":"#\n\n\nStart#\n\nWrite something to build your own docs! üéÅ","routePath":"/hello","lang":"","toc":[{"text":"Start","id":"start","depth":2,"charIndex":3}],"domain":"","frontmatter":{},"version":""},{"id":6,"title":"","content":" * LIP: 1\n * Layer: Core Encoding\n * Title: Extend Tag 10 for Sub-Typed Data (IxData Field)\n * Author: Allwin Ketnawang\n * Created: 2025-04-27\n * Superseded-By: 6\n * Status: Replaced\n\n\nAbstract#\n\nThis LIP proposes replacing the original CTE v1.0 Tag 10 \"Index Reference\" field\nwith a more versatile structure named the \"Index and Extended Data Field\" (or\n\"IxData Field\" for short). This new structure utilizes the previously reserved\nbits 1-0 of the header byte to introduce four sub-types, enabling the efficient\nencoding of: legacy 4-bit indices, standard variable-length integers\n(ULEB128/SLEB128), common fixed-size data types (integers, floats), and\nsingle-byte constants (including booleans). This enhances the expressiveness and\nefficiency of the CTE format.\n\n\nMotivation#\n\nThe original CTE v1.0 specification defined the Tag 10 field solely as a 1-byte\nreference containing a 4-bit index (0-15) into preceding key or signature lists.\nWhile useful, this is limiting. Applications built on CTE often require encoding\nother fundamental data types compactly, such as:\n\n 1. Integers larger than 15 or needing variable-length encoding for efficiency.\n 2. Signed integers.\n 3. Standard fixed-size types like int32, uint64, float, and double without the\n    overhead of the generic Command Data field.\n 4. Atomic boolean values (true/false) or other single-byte markers (like null)\n    in a highly compact, unambiguous way.\n\nThis proposal addresses these needs by repurposing the Tag 10 field. By using\nthe two previously reserved bits (1-0) as a sub-type selector, we can introduce\nmultiple data formats under a single tag, significantly increasing the utility\nand efficiency of the CTE format while maintaining partial backwards\ncompatibility for the original index reference use case.\n\n\nSpecification#\n\nThis LIP replaces Section 4.3 of the CTE v1.0 specification document entirely\nwith the following:\n\n--------------------------------------------------------------------------------\n\n\n4.3. Index and Extended Data Field (IxData Field) (Tag 10)#\n\n * Tag: 10\n * Purpose: Encodes different types of data including simple list indices,\n   variable-length integers using standard encodings, standard fixed-size data\n   types, and single-byte constants or markers.\n * Identification: Fields of this type are identified by the Tag 10 in bits 7-6\n   of the header byte. The specific interpretation and format are determined by\n   the Sub-Type field located in bits 1-0 (SS) of the header byte.\n * General Header Byte Structure:\n   \n   BITS   FIELD             DESCRIPTION\n   7-6    Tag (10)          Identifies this as the IxData Field family.\n   5-2    Sub-Data (XXXX)   4-bit value whose meaning depends on the Sub-Type (SS)\n                            field.\n   1-0    Sub-Type (SS)     Determines the format and interpretation (00, 01, 10, 11).\n\n * Endianness Note: Unless otherwise specified, all multi-byte numerical data\n   within CTE v1.1 fields (including sub-types defined below and Command Data)\n   MUST be encoded using Little-Endian byte order. LEB128 encodings follow their\n   own standard byte order.\n\n--------------------------------------------------------------------------------\n\n4.3.1. Sub-Type 00: Legacy Index Reference#\n\n * Sub-Type Code (SS): 00\n * Purpose: Provides a zero-based index referencing an item within the preceding\n   Public Key List (Section 4.1) or Signature List (Section 4.2). The context\n   determines which list is being referenced. This maintains compatibility with\n   CTE v1.0.\n * Format:\n   * Header Byte: 10 IIII 00\n     \n     BITS   FIELD           DESCRIPTION\n     7-6    Tag (10)        IxData Field family.\n     5-2    Index (IIII)    The 4-bit index value (0-15).\n     1-0    Sub-Type (00)   Specifies Legacy Index Reference format.\n   \n   * Data: No following data bytes.\n * Constraints: The Index value (IIII) MUST correspond to a valid position\n   within the relevant list.\n * Total Size: 1 byte.\n * Reserved Values: None within this sub-type.\n * Example (Reference Index 5): Header Byte: 10 0101 00 = 0x94\n\n--------------------------------------------------------------------------------\n\n4.3.2. Sub-Type 01: Variable-Length Encoded Integer (Varint)#\n\n * Sub-Type Code (SS): 01\n * Purpose: Encodes a signed or unsigned integer value using standard\n   variable-length encoding schemes (LEB128) or represents the value 0 directly.\n * Format:\n   * Header Byte: 10 EEEE 01\n     \n     BITS   FIELD                    DESCRIPTION\n     7-6    Tag (10)                 IxData Field family.\n     5-2    Encoding Scheme (EEEE)   Specifies the encoding method or direct value (see table\n                                     below).\n     1-0    Sub-Type (01)            Specifies Varint format.\n   \n   * Data: For LEB128 schemes, followed by the bytes constituting the\n     variable-length encoded integer according to the relevant standard. The\n     number of data bytes is determined by the LEB128 encoding itself (via\n     continuation bits).\n * Encoding Schemes (EEEE):\n   \n   EEEE (BIN)   EEEE (DEC)   HEADER BYTE (HEX)   ENCODING SCHEME / VALUE   NOTES                                           SIZE (BYTES)\n   0000         0            0x81                Value 0                   Represents the integer value 0 directly.        1 (Header only)\n   0001         1            0x85                ULEB128                   Unsigned LEB128 encoded integer data follows.   1 + Data Length\n   0010         2            0x89                SLEB128                   Signed LEB128 encoded integer data follows.     1 + Data Length\n   0011         3            0x8D                Reserved                  For future variable-length encoding schemes.    -\n   ...          ...          ...                 ...                       (Codes 3-15 are Reserved)                       ...\n   1111         15           0xBD                Reserved                  For future variable-length encoding schemes.    -\n\n * Constraints:\n   * Decoders MUST correctly implement ULEB128 and SLEB128 decoding.\n   * While LEB128 can encode arbitrarily large integers, implementations MAY\n     impose practical limits based on transaction size constraints or\n     application needs (e.g., limiting to 64-bit or 128-bit range).\n * Total Size: 1 byte for value 0; 1 + Length(LEB128 Data) bytes otherwise.\n * Reserved Values: Encoding scheme codes 3 through 15 are reserved.\n * Example 1 (Value 300 / 0x12C using ULEB128):\n   * ULEB128 requires 2 data bytes: 0xAC, 0x02. EEEE = 0001.\n   * Header Byte: 10 0001 01 = 0x85\n   * Following Data: 0xAC, 0x02\n * Example 2 (Value -100 using SLEB128):\n   * SLEB128 requires 2 data bytes: 0x9C, 0x7F. EEEE = 0010.\n   * Header Byte: 10 0010 01 = 0x89\n   * Following Data: 0x9C, 0x7F\n\n--------------------------------------------------------------------------------\n\n4.3.3. Sub-Type 10: Fixed Data Type#\n\n * Sub-Type Code (SS): 10\n * Purpose: Encodes a value belonging to a standard, fixed-size data type\n   identified by a type code.\n * Format:\n   * Header Byte: 10 TTTT 10\n     \n     BITS   FIELD              DESCRIPTION\n     7-6    Tag (10)           IxData Field family.\n     5-2    Type Code (TTTT)   Specifies the fixed data type (see table below).\n     1-0    Sub-Type (10)      Specifies Fixed Data Type format.\n   \n   * Data: Followed by the number of bytes corresponding to the specified Type\n     Code. Data is encoded in Little-Endian byte order where applicable\n     (multi-byte integers, floats).\n * Type Codes (TTTT):\n   \n   TTTT (BIN)   TTTT (DEC)   DATA TYPE   SIZE (BYTES)   NOTES\n   0000         0            int8_t      1              Signed 8-bit integer\n   0001         1            int16_t     2              Signed 16-bit integer\n   0010         2            int32_t     4              Signed 32-bit integer\n   0011         3            int64_t     8              Signed 64-bit integer\n   0100         4            uint8_t     1              Unsigned 8-bit integer\n   0101         5            uint16_t    2              Unsigned 16-bit integer\n   0110         6            uint32_t    4              Unsigned 32-bit integer\n   0111         7            uint64_t    8              Unsigned 64-bit integer\n   1000         8            float       4              IEEE 754 Single-Precision\n   1001         9            double      8              IEEE 754 Double-Precision\n   1010         10           Reserved    -              For future use\n   ...          ...          ...         ...            (Codes 10-15 are Reserved)\n   1111         15           Reserved    -              For future use\n\n * Constraints: The data following the header MUST match the size and format\n   required by the specified Type Code.\n * Total Size: 1 + Size(Type[TTTT]) bytes.\n * Reserved Values: Type codes 10 through 15 are reserved.\n * Example (Value -100 as int16_t):\n   * -100 is 0xFF9C (Little-Endian: 9C FF). TTTT = 0001.\n   * Header Byte: 10 0001 10 = 0x86\n   * Following Data: 0x9C, 0xFF\n\n--------------------------------------------------------------------------------\n\n4.3.4. Sub-Type 11: Single-Byte Constant/Marker#\n\n * Sub-Type Code (SS): 11\n * Purpose: Encodes specific predefined constant values (like boolean\n   true/false) or semantic markers using only a single byte. The meaning is\n   determined directly by the Value Code.\n * Format:\n   * Header Byte: 10 XXXX 11 (The header byte is the entire field)\n     \n     BITS   FIELD               DESCRIPTION\n     7-6    Tag (10)            IxData Field family.\n     5-2    Value Code (XXXX)   Specifies the constant or marker value (0-15).\n     1-0    Sub-Type (11)       Specifies Single-Byte Constant/Marker format.\n   \n   * Data: No following data bytes.\n * Value Codes (XXXX):\n   \n   XXXX (BIN)   XXXX (DEC)   HEADER BYTE (HEX)   DEFINED MEANING   NOTES\n   0000         0            0x83                false             Boolean false value\n   0001         1            0x87                true              Boolean true value\n   0010         2            0x8B                Reserved          For future use\n   ...          ...          ...                 ...               (Codes 2-15 are Reserved)\n   1111         15           0xBF                Reserved          e.g., For Null, Separator\n\n * Constraints: Implementations should recognize the defined constant values.\n * Total Size: 1 byte.\n * Reserved Values: Value codes 2 through 15 are reserved for future standard\n   constants or markers.\n * Example (Representing false): The single byte 10 0000 11 = 0x83 is used.\n\n--------------------------------------------------------------------------------\n\n\nRationale#\n\n * Sub-Typing: Utilizing the two previously reserved bits (1-0) of the Tag 10\n   header byte allows extending functionality significantly without consuming a\n   new top-level tag, preserving the core 2-bit tag structure of CTE.\n * Varint (SS=01): Adopting ULEB128 and SLEB128 provides standard, efficient\n   variable-length encodings for unsigned and signed integers, respectively.\n   Including a direct representation for '0' (EEEE=0000) optimizes the most\n   common default integer value.\n * Fixed Types (SS=10): Directly encoding common fixed-width types (integers up\n   to 64 bits, float, double) is often more convenient and potentially faster to\n   decode than using variable-length encodings or the generic Command Data field\n   for these types. Little-Endian is chosen as a common standard.\n * Single-Byte Constants (SS=11): Allocating a dedicated sub-type for\n   single-byte constants like true and false provides an unambiguous and highly\n   efficient (1 byte) representation. This keeps the SS=10 (Fixed Type) logic\n   consistent (header always implies following data) and leaves room in SS=11\n   for other markers (e.g., null, separators) if needed later.\n\n\nBackwards Compatibility#\n\nThis proposal introduces new interpretations for the Tag 10 field based on the\nvalue of bits 1-0.\n\n * Partially Compatible: CTE processors compliant only with v1.0 will correctly\n   interpret the Legacy Index Reference (SS=00) sub-type, as its format (10 IIII\n   00) remains unchanged.\n * Incompatible: V1.0 processors will not recognize or correctly decode data\n   encoded using the new sub-types (SS=01, SS=10, SS=11). Encountering these\n   formats will likely lead to parsing errors or data misinterpretation.\n\nAdoption of this LIP requires updating CTE processors to recognize and handle\nall four defined sub-types of the Tag 10 IxData Field. This change effectively\ndefines CTE v1.1.\n\n\nSecurity Considerations#\n\n * LEB128 Decoding (SS=01): Implementations decoding ULEB128 and SLEB128 must\n   protect against potential resource exhaustion attacks. Maliciously crafted\n   long sequences (many bytes with continuation bits set) could cause excessive\n   CPU usage or memory allocation during decoding. Robust decoders should\n   enforce limits on the number of bytes read for a single LEB128 value or check\n   the magnitude of the partially decoded value against reasonable bounds (e.g.,\n   max 128 bits, or application-specific limits) related to the overall\n   transaction size limit.\n * Fixed Type Decoding (SS=10): Decoders must ensure sufficient bytes are\n   available in the input buffer before attempting to read the data associated\n   with a fixed type to prevent buffer over-reads. The required size is known\n   directly from the TTTT code.\n\n\nCopyright#\n\nThis LIP is licensed under the MIT License, in alignment with the main LEA\nProject License.","routePath":"/lips/LIP-0001","lang":"","toc":[{"text":"Abstract","id":"abstract","depth":2,"charIndex":184},{"text":"Motivation","id":"motivation","depth":2,"charIndex":767},{"text":"Specification","id":"specification","depth":2,"charIndex":1789},{"text":"4.3. Index and Extended Data Field (IxData Field) (Tag `10`)","id":"43-index-and-extended-data-field-ixdata-field-tag-10","depth":3,"charIndex":-1},{"text":"4.3.1. Sub-Type `00`: Legacy Index Reference","id":"431-sub-type-00-legacy-index-reference","depth":4,"charIndex":-1},{"text":"4.3.2. Sub-Type `01`: Variable-Length Encoded Integer (Varint)","id":"432-sub-type-01-variable-length-encoded-integer-varint","depth":4,"charIndex":-1},{"text":"4.3.3. Sub-Type `10`: Fixed Data Type","id":"433-sub-type-10-fixed-data-type","depth":4,"charIndex":-1},{"text":"4.3.4. Sub-Type `11`: Single-Byte Constant/Marker","id":"434-sub-type-11-single-byte-constantmarker","depth":4,"charIndex":-1},{"text":"Rationale","id":"rationale","depth":2,"charIndex":10585},{"text":"Backwards Compatibility","id":"backwards-compatibility","depth":2,"charIndex":11767},{"text":"Security Considerations","id":"security-considerations","depth":2,"charIndex":12484},{"text":"Copyright","id":"copyright","depth":2,"charIndex":13346}],"domain":"","frontmatter":{},"version":""},{"id":7,"title":"","content":" * LIP: 2\n * Layer: Core Encoding\n * Title: Typed Crypto Schemes and Segregated PQC Signature Proofs\n * Author: Allwin Ketnawang\n * Created: 2025-04-28\n * Superseded-By: 6\n * Status: Replaced\n\n\nAbstract#\n\nThis LIP proposes extending the CTE specification to support multiple\ncryptographic schemes, including Post-Quantum Cryptography (PQC) algorithms like\nSLH-DSA (also known as SPHINCS+). It utilizes the two previously reserved\npadding bits within the header bytes of the Public Key List (Tag 00) and\nSignature List (Tag 01) fields to encode the specific cryptographic scheme being\nused. For PQC signatures, which are typically very large, this proposal adopts a\nsegregated proof model: only a 32-byte BLAKE3 hash of the PQC signature is\nstored on-chain within the Signature List field, while the full signature proof\nis expected to be distributed via a separate mechanism. This allows LEA\nblockchain transactions to gain PQC resistance while maintaining the core\ncompactness principle of CTE.\n\n\nMotivation#\n\nAs quantum computing advances, blockchains need to transition to PQC algorithms\nto ensure long-term security. However, many PQC signatures are significantly\nlarger than traditional signatures (e.g., Ed25519 used in CTE v1.0), potentially\nexceeding CTE's strict Maximum Transaction Size limit (1232 bytes). Storing\nthese large signatures directly on-chain would undermine CTE's efficiency and\ncompactness.\n\nThis proposal aims to:\n\n 1. Introduce a mechanism to identify different cryptographic schemes (standard\n    ECC and PQC) within the existing CTE structure without consuming new tags.\n 2. Enable the use of PQC public keys (specifically SLH-DSA variants) within\n    transactions.\n 3. Allow verification of PQC signatures without storing the entire large\n    signature on-chain, by committing only to a secure hash (BLAKE3) of the\n    signature within the transaction data.\n\nThis approach maintains small transaction sizes while paving the way for quantum\nresistance.\n\n\nSpecification#\n\nThis LIP modifies Sections 4.1 and 4.2 of the CTE v1.0 specification by\nassigning meaning to the previously reserved bits 1-0 of their respective header\nbytes.\n\n--------------------------------------------------------------------------------\n\n\n4.1. Public Key List (Tag 00) - Updated#\n\n * Tag: 00\n * Purpose: Encodes a list of one or more public keys used within the\n   transaction. The type and size of the keys are determined by the header\n   byte's Type Code bits.\n * Format:\n   * Header Byte:\n     \n     BITS   FIELD            DESCRIPTION\n     7-6    Tag (00)         Identifies this as a Public Key List.\n     5-2    Length (N)       Number of keys in the list (1-15).\n     1-0    Type Code (TT)   Specifies the cryptographic scheme (see table below).\n   \n   * Data: Followed by N contiguous public keys. The size of each key depends on\n     the Type Code.\n * Type Codes (TT):\n   \n   TT (BIN)   TT (DEC)   CRYPTOGRAPHIC SCHEME   KEY SIZE (BYTES)   NOTES\n   00         0          Ed25519                32                 CTE v1.0 Default\n   01         1          SLH-DSA-SHA2-128f      32                 SPHINCS+ variant public key\n   10         2          SLH-DSA-SHA2-192f      48                 SPHINCS+ variant public key\n   11         3          SLH-DSA-SHA2-256f      64                 SPHINCS+ variant public key\n\n * Constraints:\n   * The Length field (N) must be between 1 and 15.\n   * The total size = 1 + (N * Size(Type[TT])) bytes. Implementations must\n     consider the overall transaction size limit.\n\n--------------------------------------------------------------------------------\n\n\n4.2. Signature List (Tag 01) - Updated#\n\n * Tag: 01\n * Purpose: Encodes a list of one or more cryptographic signatures or signature\n   hashes used to authorize the transaction. The format (full signature or hash)\n   and the underlying scheme are determined by the header byte's Type Code bits.\n * Format:\n   * Header Byte:\n     \n     BITS   FIELD            DESCRIPTION\n     7-6    Tag (01)         Identifies this as a Signature List.\n     5-2    Length (N)       Number of signatures/hashes in list (1-15).\n     1-0    Type Code (TT)   Specifies the scheme and format (see table below).\n   \n   * Data: Followed by N contiguous signatures or signature hashes. The size of\n     each item depends on the Type Code.\n * Type Codes (TT):\n   \n   TT (BIN)   TT (DEC)   CRYPTOGRAPHIC SCHEME / FORMAT                ITEM SIZE (BYTES)   NOTES\n   00         0          Ed25519 Signature                            64                  CTE v1.0 Default, full signature\n   01         1          BLAKE3 Hash of SLH-DSA-SHA2-128f Signature   32                  256-bit hash of the corresponding full PQC signature proof\n   10         2          BLAKE3 Hash of SLH-DSA-SHA2-192f Signature   32                  256-bit hash of the corresponding full PQC signature proof\n   11         3          BLAKE3 Hash of SLH-DSA-SHA2-256f Signature   32                  256-bit hash of the corresponding full PQC signature proof\n\n * Constraints:\n   * The Length field (N) must be between 1 and 15.\n   * For TT = 01, 10, 11, the data represents a 32-byte hash generated using the\n     BLAKE3 cryptographic hash function on the full PQC signature.\n   * The validation process for TT = 01, 10, 11 requires obtaining the\n     corresponding full PQC signature proof from an external source (off-chain\n     mechanism), verifying the proof against the public key, and then hashing\n     the proof with BLAKE3 to compare against the 32-byte hash stored in this\n     field.\n   * Total size = 1 + (N * Size(Type[TT])) bytes.\n\n--------------------------------------------------------------------------------\n\n\nOff-Chain Proof Distribution#\n\nThe mechanism for distributing and retrieving the full PQC signature proofs\ncorresponding to the on-chain hashes (TT = 01, 10, 11 in Tag 01) is outside the\nscope of this core encoding specification but is a critical component required\nfor validation. Implementations MUST ensure a reliable and secure system for\nthis purpose.\n\n--------------------------------------------------------------------------------\n\n\nRationale#\n\n * Leveraging Reserved Bits: Using the 2 reserved bits in the Tag 00 and 01\n   headers is the intended mechanism for extending CTE functionality without\n   consuming new tags, maintaining the compact 2-bit tag structure. This\n   provides 4 type codes, sufficient for the default scheme and the initial set\n   of PQC algorithms.\n * Segregated Proofs: Storing only a hash of large PQC signatures on-chain\n   drastically reduces the data footprint, preserving CTE's suitability for\n   constrained environments. This avoids a potentially massive increase in the\n   Maximum Transaction Size.\n * BLAKE3 Hash: BLAKE3 is chosen as a modern, high-performance, and secure\n   cryptographic hash function suitable for generating the 32-byte (256-bit)\n   on-chain commitments.\n * PQC Algorithm Choice: SLH-DSA (SPHINCS+) is selected as a prominent stateless\n   hash-based signature scheme, known for its strong security properties against\n   quantum adversaries. The specific variants (128f, 192f, 256f) offer different\n   security/performance trade-offs.\n\n\nBackwards Compatibility#\n\n * Transactions using only Type Code 00 in the Public Key List and Signature\n   List headers remain compatible with CTE v1.0 / v1.1 parsers that ignore or\n   expect the padding bits to be zero.\n * Transactions utilizing the new Type Codes (01, 10, 11) in either header are\n   incompatible with older parsers. These parsers will likely fail or\n   misinterpret the data due to unexpected key/signature sizes or formats.\n * Adoption of this LIP requires updating CTE processors to recognize and handle\n   all defined Type Codes for Tags 00 and 01. This change effectively defines\n   CTE v1.2 (or potentially CTE v2.0 depending on community consensus regarding\n   the significance of PQC integration and the segregated proof model).\n\n\nSecurity Considerations#\n\n * Off-Chain Proof Availability & Integrity: The security of the entire system\n   heavily relies on the external mechanism used to distribute and retrieve the\n   full PQC signature proofs. This mechanism must guarantee proof availability\n   for validation and resist tampering or censorship. Delays or failures in\n   retrieving proofs can stall transaction validation. The design of this\n   mechanism is critical.\n * Validation Logic: Validators must implement robust logic to fetch the correct\n   off-chain proof, verify it using the appropriate PQC algorithm (indicated by\n   the Type Code) against the public key (also typed), and then hash the\n   verified proof with BLAKE3 to compare against the on-chain hash. Any failure\n   in this chain invalidates the transaction authorization.\n * PQC Public Key Sizes: While this LIP allows specifying different PQC public\n   key types, including the full keys in the Public Key List still consumes\n   transaction space (32, 48, or 64 bytes per key). Applications should consider\n   the impact on the overall transaction size limit.\n\n\nCopyright#\n\nThis LIP is licensed under the MIT License, in alignment with the main LEA\nProject License.","routePath":"/lips/LIP-0002","lang":"","toc":[{"text":"Abstract","id":"abstract","depth":2,"charIndex":193},{"text":"Motivation","id":"motivation","depth":2,"charIndex":997},{"text":"Specification","id":"specification","depth":2,"charIndex":1983},{"text":"4.1. Public Key List (Tag `00`) - Updated","id":"41-public-key-list-tag-00---updated","depth":3,"charIndex":-1},{"text":"4.2. Signature List (Tag `01`) - Updated","id":"42-signature-list-tag-01---updated","depth":3,"charIndex":-1},{"text":"Off-Chain Proof Distribution","id":"off-chain-proof-distribution","depth":3,"charIndex":5679},{"text":"Rationale","id":"rationale","depth":2,"charIndex":6120},{"text":"Backwards Compatibility","id":"backwards-compatibility","depth":2,"charIndex":7177},{"text":"Security Considerations","id":"security-considerations","depth":2,"charIndex":7934},{"text":"Copyright","id":"copyright","depth":2,"charIndex":9039}],"domain":"","frontmatter":{},"version":""},{"id":8,"title":"","content":" * LIP: 3\n * Layer: Meta/Process\n * Title: LIP Structure and Process\n * Author: Allwin Ketnawang\n * Created: 2025-04-28\n * Status: Proposed\n\n\nAbstract#\n\nThis LIP defines the standard structure, required sections, header fields, and\nlifecycle statuses for LEA Improvement Proposals (LIPs). Establishing a\nconsistent format and process facilitates clear communication, effective review,\nand organized tracking of proposed changes to the LEA protocol and ecosystem.\nThis document itself follows the proposed standard.\n\n\nMotivation#\n\nAs the LEA project evolves, a standardized process for proposing, discussing,\nand tracking changes becomes essential. Currently, there is no formal definition\nfor how improvement proposals should be structured or managed. This leads to\npotential inconsistencies, makes proposals harder to compare and review, and\ncomplicates tracking their progress. LIP-3 aims to rectify this by establishing\na clear template and defined lifecycle for all future LIPs, improving clarity\nand efficiency in the development process.\n\n\nSpecification#\n\nAll LEA Improvement Proposals MUST adhere to the following Markdown structure\nand include the defined header fields and sections.\n\n\n1. LIP Header Preamble#\n\nEach LIP must begin with a header section containing the following fields:\n\n * LIP: (Required) The LIP number, assigned sequentially (e.g., 3).\n * Layer: (Required) The area of the LEA protocol or ecosystem affected. See\n   Layer Definitions below.\n * Title: (Required) A concise title summarizing the proposal's content.\n * Author: (Required) A list of the author(s) or primary champion(s) of the\n   proposal, using names or handles.\n * Discussions-To: (Optional) A URL pointing to the primary discussion forum,\n   issue tracker thread, or mailing list archive for this LIP.\n * Created: (Required) The date the LIP was first formally drafted (YYYY-MM-DD).\n * Updated: (Optional) The date the LIP was last significantly updated\n   (YYYY-MM-DD).\n * Requires: (Optional) A list of LIP number(s) that this LIP depends on.\n * Replaces: (Optional) A list of LIP number(s) that this LIP renders obsolete.\n * Superseded-By: (Optional) A list of LIP number(s) that render this LIP\n   obsolete.\n * Status: (Required) The current stage of the LIP in its lifecycle. See Status\n   Definitions below.\n\n\n2. LIP Body Sections#\n\nFollowing the header, each LIP must include these sections:\n\n * Abstract: A brief (~200 word) summary of the proposal.\n * Motivation: Explanation of the problem being solved and the rationale for the\n   proposal.\n * Specification: Detailed technical description of the proposed changes.\n * Rationale: Justification for design choices and discussion of alternatives\n   considered.\n * Backwards Compatibility: Analysis of compatibility with existing systems and\n   transition plans if applicable.\n * Security Considerations: Assessment of potential security impacts.\n * Copyright: Statement of the license under which the LIP is released\n   (typically CC0 waiver or MIT License).\n\n\n3. Layer Definitions#\n\nThe Layer field categorizes the LIP. Defined layers are:\n\n * Core Encoding: Changes to data serialization (e.g., CTE).\n * Consensus: Changes to network agreement rules.\n * Networking: Changes to peer-to-peer protocols.\n * API/RPC: Changes to node interaction interfaces.\n * Application: Standards for applications built on LEA.\n * Meta/Process: Changes to the LIP process itself (like this LIP).\n\n\n4. Status Definitions#\n\nThe Status field tracks the LIP's lifecycle stage:\n\n * Idea: Informal concept stage.\n * Draft: Initial formal written version for discussion.\n * Proposed: Mature draft ready for formal review.\n * Approved / Accepted: Formally accepted for implementation.\n * Active / Final: Implemented and part of the official specification/protocol.\n * Deferred: Postponed for later consideration.\n * Rejected: Formally declined.\n * Withdrawn: Retracted by the author(s).\n * Replaced / Superseded: Made obsolete by a newer LIP.\n\n\n5. LIP Template Markdown#\n\nThe following Markdown code block represents the standard template to be used\nfor new LIPs:\n\n\n\n\nRationale#\n\nAdopting a standardized structure based on common practices in other blockchain\nprojects (like BIPs/EIPs) provides immediate clarity and familiarity. The chosen\nsections cover the essential aspects needed to understand, evaluate, and\nimplement a proposal. Defining layers helps categorize proposals, while defined\nstatuses provide a clear view of the proposal lifecycle. Making this definition\nitself a LIP ensures the process is self-documenting and can be updated via the\nsame mechanism if needed.\n\n\nBackwards Compatibility#\n\nThis LIP defines a process and does not directly impact the LEA protocol's\ntechnical backwards compatibility. It applies to LIPs created after its\nacceptance.\n\n\nSecurity Considerations#\n\nStandardizing the proposal process does not introduce direct technical\nvulnerabilities. However, adherence to the process, particularly the Security\nConsiderations section within each LIP, is crucial for maintaining the overall\nsecurity of the LEA protocol as it evolves. Ensuring clear documentation and\nreview helps prevent unintentional security issues.\n\n\nCopyright#\n\nThis LIP is licensed under the MIT License, in alignment with the main LEA\nProject License.","routePath":"/lips/LIP-0003","lang":"","toc":[{"text":"Abstract","id":"abstract","depth":2,"charIndex":141},{"text":"Motivation","id":"motivation","depth":2,"charIndex":516},{"text":"Specification","id":"specification","depth":2,"charIndex":1045},{"text":"1. LIP Header Preamble","id":"1-lip-header-preamble","depth":3,"charIndex":1193},{"text":"2. LIP Body Sections","id":"2-lip-body-sections","depth":3,"charIndex":2308},{"text":"3. Layer Definitions","id":"3-layer-definitions","depth":3,"charIndex":3011},{"text":"4. Status Definitions","id":"4-status-definitions","depth":3,"charIndex":3432},{"text":"5. LIP Template Markdown","id":"5-lip-template-markdown","depth":3,"charIndex":3971},{"text":"Rationale","id":"rationale","depth":2,"charIndex":4094},{"text":"Backwards Compatibility","id":"backwards-compatibility","depth":2,"charIndex":4608},{"text":"Security Considerations","id":"security-considerations","depth":2,"charIndex":4795},{"text":"Copyright","id":"copyright","depth":2,"charIndex":5180}],"domain":"","frontmatter":{},"version":""},{"id":9,"title":"","content":" * LIP: 4\n * Layer: Core Encoding\n * Title: Decouple Legacy Index Field from List Context\n * Author: Allwin Ketnawang\n * Created: 2025-05-01\n * Superseded-By: 6\n * Status: Replaced\n\n\nAbstract#\n\nThis LIP proposes modifying the definition and processing rules for the IxData\nField Sub-Type 00 (\"Legacy Index Reference\"), as introduced in LIP-1. While\nretaining its semantic meaning as an index into a Public Key List or Signature\nList present within the transaction, this proposal removes the requirement that\nthe index field must immediately follow the list it references. The\nresponsibility for associating the index with the correct list and performing\nthe bounds check is shifted from the raw decoder to the higher-level application\nlogic consuming the decoded stream.\n\n\nMotivation#\n\nThe current specification (CTE v1.1 / LIP-1) requires the IxData Sub-Type 00\nfield (10 IIII 00) to immediately follow the Public Key or Signature List it\nreferences. This restricts its use, particularly within Command Data (Tag 11).\nThis proposal allows the 10xxxx00 field to appear anywhere, including within the\nencoded payload of a command (e.g., smart contract arguments). This enables\ncommands or contracts to compactly reference items (like public keys or\nsignatures) from lists defined earlier in the transaction, leaving the\ninterpretation (which list is referenced) and bounds checking to the application\nor contract logic.\n\n\nSpecification#\n\nThis LIP modifies the description and constraints associated with Section 4.3.1\n(\"Sub-Type 00: Legacy Index Reference\") of the CTE specification, as previously\ndefined by LIP-1. The field format remains unchanged.\n\nThe modified Section 4.3.1 reads as follows:\n\n--------------------------------------------------------------------------------\n\n4.3.1. Sub-Type 00: List Index Reference#\n\n * Sub-Type Code (SS): 00\n * Purpose: Provides a zero-based index referencing an item within a Public Key\n   List (Section 4.1) or Signature List (Section 4.2) that exists elsewhere\n   within the same CTE transaction.\n * Format:\n   * Header Byte: 10 IIII 00\n     \n     BITS   FIELD           DESCRIPTION\n     7-6    Tag (10)        IxData Field family.\n     5-2    Index (IIII)    The 4-bit index value (0-15).\n     1-0    Sub-Type (00)   Specifies List Index Reference format.\n   \n   * Data: No following data bytes.\n * Constraints:\n   * The Index value (IIII) MUST correspond to a valid position within the\n     intended target list (Public Key or Signature List).\n   * The association between this index field and its target list (i.e., whether\n     it refers to the Public Key List or the Signature List) is not defined at\n     the raw CTE encoding layer but MUST be defined by the application or\n     higher-level protocol interpreting the CTE stream.\n   * The validation that the Index value is within the bounds of the target list\n     (Index < list_size) MUST be performed by the application logic, using the\n     decoded index and the size of the appropriate target list (obtained when\n     decoding that list).\n * Total Size: 1 byte.\n * Reserved Values: None within this sub-type.\n * Example (Encoding index 1): Header Byte: 10 0001 00 = 0x84. (The application\n   logic determines if this refers to the PubKey list or Sig list and performs\n   bounds checks accordingly).\n\n--------------------------------------------------------------------------------\n\nSummary of Changes:\n\n 1. The section title is changed back to \"List Index Reference\" (or similar) to\n    reflect its purpose.\n 2. The description clarifies that the referenced list can be elsewhere in the\n    transaction, not necessarily immediately preceding.\n 3. Explicit constraints are added stating that:\n    * The target list association is application-defined.\n    * The bounds checking responsibility lies with the application, not the raw\n      decoder.\n 4. The previous decoder constraint requiring last_list_count > 0 is removed\n    from the raw decoding step for this field.\n\n\nRationale#\n\nThis approach balances flexibility with semantic clarity:\n\n * Flexibility: Allows indices to be placed anywhere, including within Command\n   Data payloads, enabling more complex or optimized transaction structures and\n   smart contract interactions.\n * Preserved Meaning: The field (10xxxx00) retains its specific meaning as a\n   list index, preventing it from being overloaded as a generic 4-bit integer,\n   which could lead to ambiguity.\n * Clear Responsibility: Explicitly defines that the context (which list is\n   targeted) and bounds validation are application-level concerns. The raw CTE\n   decoder's job is simply to extract the 4-bit index value from this field\n   type.\n * Minimal Encoding Change: Achieves the goal without altering the byte-level\n   format of the field itself.\n\n\nSecurity Considerations#\n\n * Application-Level Validation Crucial: The primary security consideration is\n   ensuring that the application logic correctly associates each index with its\n   intended target list and performs rigorous bounds checking. Failure to do so\n   could lead to vulnerabilities, such as using the wrong public key for\n   verification or referencing non-existent signatures.\n\n\nCopyright#\n\nThis LIP is licensed under the MIT License, in alignment with the main LEA\nProject License.","routePath":"/lips/LIP-0004","lang":"","toc":[{"text":"Abstract","id":"abstract","depth":2,"charIndex":182},{"text":"Motivation","id":"motivation","depth":2,"charIndex":772},{"text":"Specification","id":"specification","depth":2,"charIndex":1420},{"text":"4.3.1. Sub-Type `00`: List Index Reference","id":"431-sub-type-00-list-index-reference","depth":4,"charIndex":-1},{"text":"Rationale","id":"rationale","depth":2,"charIndex":3975},{"text":"Security Considerations","id":"security-considerations","depth":2,"charIndex":4778},{"text":"Copyright","id":"copyright","depth":2,"charIndex":5174}],"domain":"","frontmatter":{},"version":""},{"id":10,"title":"","content":" * LIP: 5\n * Layer: Core Encoding\n * Title: Generalize Vectors with Explicit Entry Sizes\n * Author: Allwin Ketnawang\n * Created: 2025-07-03\n * Replaces: 2\n * Superseded-By: 6\n * Status: Replaced\n\n\nAbstract#\n\nThis LIP proposes a fundamental, breaking change to the CTE specification. It\nrenames Public Key List and Signature List to Public Key Vector and Signature\nVector, and renames Legacy Index Reference to Vector Index.\n\nCrucially, it replaces the concept of a crypto-specific type code (as defined in\nLIP-2) with a generic entry size code. The TT bits in the vector headers will\nnow explicitly define the byte size of each element in the vector's data\npayload. This simplifies the core CTE parsing logic by decoupling it from\ncryptographic scheme specifics, making the format more flexible and\nforward-compatible. This proposal renders LIP-2 obsolete.\n\n\nMotivation#\n\nLIP-2 coupled the TT type code directly to a cryptographic algorithm (e.g.,\nTT=00 for Ed25519). While this provided semantic meaning at the parsing layer,\nit also made the core format rigid. Adding a new algorithm or a variant with the\nsame key size would require a new TT code and a specification update.\n\nThis proposal simplifies the parser's responsibility to a purely structural one:\nread a vector of N items, where each item is X bytes long. The TT code now\nsimply defines 'X'. The semantic interpretation of what those bytes represent\n(e.g., an Ed25519 key vs. an SLH-DSA key) is moved to the application layer,\nwhere it ultimately matters. This makes the base CTE format more generic and\nextensible. The renaming to \"Vector\" and \"Vector Index\" reflects this more\ngeneric, structural nature.\n\n\nSpecification#\n\nThis LIP replaces the specifications for Tag 00 and Tag 01 as defined in LIP-2\nand renames the IxData Sub-Type 00.\n\n--------------------------------------------------------------------------------\n\n\n4.1. Public Key Vector (Tag 00) - Updated#\n\n * Tag: 00\n * Purpose: Encodes a vector of one or more public keys. The size of each key is\n   determined by the header byte's Entry Size Code.\n * Header Byte:\n   \n   BITS   FIELD                  DESCRIPTION\n   7-6    Tag (00)               Identifies this as a Public Key Vector.\n   5-2    Length (N)             Number of keys in the vector (1-15).\n   1-0    Entry Size Code (TT)   Specifies the size of each key (see table below).\n\n * Entry Size Codes (TT):\n   \n   TT (BIN)   KEY SIZE (BYTES)\n   00         32\n   01         64\n   10         128\n   11         Unused\n\n--------------------------------------------------------------------------------\n\n\n4.2. Signature Vector (Tag 01) - Updated#\n\n * Tag: 01\n * Purpose: Encodes a vector of one or more cryptographic signatures or\n   signature hashes. The size of each item is determined by the header byte's\n   Entry Size Code.\n * Header Byte:\n   \n   BITS   FIELD                  DESCRIPTION\n   7-6    Tag (01)               Identifies this as a Signature Vector.\n   5-2    Length (N)             Number of items in the vector (1-15).\n   1-0    Entry Size Code (TT)   Specifies the size of each item (see table below).\n\n * Entry Size Codes (TT):\n   \n   TT (BIN)   ITEM SIZE (BYTES)\n   00         32\n   01         64\n   10         128\n   11         29792\n\n--------------------------------------------------------------------------------\n\n\n4.3.1. Vector Index (IxData Sub-Type 00) - Updated#\n\n * Name: The field previously known as Legacy Index Reference is renamed to\n   Vector Index.\n * Purpose: Provides a zero-based index into a Public Key Vector or Signature\n   Vector. The responsibility for determining which vector is being referenced\n   lies with the application layer, as per LIP-4.\n\n--------------------------------------------------------------------------------\n\n\nRationale#\n\n * Decoupling: This change decouples the core CTE parser from the complexities\n   of cryptographic validation. The parser's job is to validate structure, not\n   semantics.\n * Flexibility: The application layer can now define the meaning of a given\n   entry size (e.g., a 32-byte public key is Ed25519 for one transaction type,\n   and PQC for another). This requires no changes to the base protocol.\n * Forward Compatibility: New cryptographic schemes can be adopted without\n   requiring new TT codes, as long as their key or signature sizes fit one of\n   the existing size slots.\n\n\nBackwards Compatibility#\n\nThis proposal is a breaking change and is not backwards compatible with\nimplementations based on LIP-2.\n\n * Parsers compliant with LIP-2 expect the TT code to define a specific\n   cryptographic scheme. They will misinterpret the data if they receive a\n   stream based on this new specification.\n * For example, under LIP-2, a Signature field with TT=00 implies a 64-byte\n   Ed25519 signature. Under this proposal, TT=00 for a Signature Vector implies\n   a 32-byte item.\n * Adoption of this LIP requires a coordinated update of all CTE processors and\n   defines a new, incompatible version of the CTE protocol.\n\n\nSecurity Considerations#\n\nThe primary security consideration is that the responsibility for correctly\ninterpreting the cryptographic context of the data is now entirely on the\napplication layer.\n\n * Application logic MUST unambiguously determine the cryptographic algorithm to\n   be used based on the transaction type or other contextual information.\n * Failure to do so could lead to severe vulnerabilities, such as attempting to\n   validate a signature with the wrong algorithm or against a key of a different\n   type. The system's security now relies on the application layer being\n   correct.\n\n\nCopyright#\n\nThis LIP is licensed under the MIT License, in alignment with the main LEA\nProject License.","routePath":"/lips/LIP-0005","lang":"","toc":[{"text":"Abstract","id":"abstract","depth":2,"charIndex":196},{"text":"Motivation","id":"motivation","depth":2,"charIndex":858},{"text":"Specification","id":"specification","depth":2,"charIndex":1671},{"text":"4.1. Public Key Vector (Tag `00`) - Updated","id":"41-public-key-vector-tag-00---updated","depth":3,"charIndex":-1},{"text":"4.2. Signature Vector (Tag `01`) - Updated","id":"42-signature-vector-tag-01---updated","depth":3,"charIndex":-1},{"text":"4.3.1. Vector Index (IxData Sub-Type `00`) - Updated","id":"431-vector-index-ixdata-sub-type-00---updated","depth":3,"charIndex":-1},{"text":"Rationale","id":"rationale","depth":2,"charIndex":3756},{"text":"Backwards Compatibility","id":"backwards-compatibility","depth":2,"charIndex":4350},{"text":"Security Considerations","id":"security-considerations","depth":2,"charIndex":4988},{"text":"Copyright","id":"copyright","depth":2,"charIndex":5587}],"domain":"","frontmatter":{},"version":""},{"id":11,"title":"","content":" * LIP: 6\n * Layer: Core Encoding\n * Title: Replace Core Transaction Encoding (CTE) with Simple Compact\n   Transaction Protocol (SCTP)\n * Author: Allwin Ketnawang\n * Created: 2025-07-07\n * Replaces: 1, 2, 4, 5\n * Status: Proposed\n\n\nAbstract#\n\nThis LIP officially deprecates the Core Transaction Encoding (CTE) and all\nassociated improvement proposals (LIPs 1, 2, 4, 5). It is replaced by a new,\nstreamlined encoding standard known as the \"Simple Compact Transaction Protocol\"\n(SCTP). This proposal formalizes the transition and contains the complete\ntechnical specification for SCTP, marking a fundamental shift in the project's\napproach to data serialization.\n\n\nMotivation#\n\nThe Core Transaction Encoding (CTE) was becoming increasingly complex. A series\nof proposed extensions (LIPs 1, 2, 4, 5) highlighted that incremental patches\nwere leading to a fragmented and overly complicated design. Rather than\ncontinuing to amend the original specification, a decision was made to develop a\nnew encoding from the ground up. The Simple Compact Transaction Protocol (SCTP)\nwas designed to be simpler, more performant, and more extensible than CTE. This\nLIP serves to formally ratify the switch, providing a clean break from the\nlegacy system and establishing a more robust foundation for future development.\n\n\nSpecification#\n\nThe Core Transaction Encoding (CTE) is deprecated. All LEA-compliant systems\nwill adopt the Simple Compact Transaction Protocol (SCTP) for all transaction\nencoding purposes.\n\nThe following is the complete technical specification for SCTP.\n\n\nOverview#\n\nA SCTP stream is a sequence of typed data fields. Each field is prefixed with a\n1-byte header that defines its type and provides metadata. All multi-byte\ninteger and floating-point values are encoded in little-endian byte order.\n\nHeader Byte#\n\nEvery data field begins with a header byte, structured as follows:\n\nMMMM TTTT\n\n * TTTT (lower 4 bits): The Type Identifier. This specifies the data type of the\n   field.\n * MMMM (upper 4 bits): Metadata. Its meaning depends on the TTTT value.\n\n--------------------------------------------------------------------------------\n\n\nType Identifiers#\n\nThe TTTT bits map to the following data types.\n\nTYPE ID   NAME      DESCRIPTION\n0         INT8      Signed 8-bit integer.\n1         UINT8     Unsigned 8-bit integer.\n2         INT16     Signed 16-bit integer.\n3         UINT16    Unsigned 16-bit integer.\n4         INT32     Signed 32-bit integer.\n5         UINT32    Unsigned 32-bit integer.\n6         INT64     Signed 64-bit integer.\n7         UINT64    Unsigned 64-bit integer.\n8         ULEB128   Unsigned LEB128-encoded integer.\n9         SLEB128   Signed LEB128-encoded integer.\n10        FLOAT32   32-bit floating-point number.\n11        FLOAT64   64-bit floating-point number.\n12        SHORT     A small integer (0-15) in a single byte.\n13        VECTOR    A generic byte array.\n14                  (Reserved for future use)\n15        EOF       End of Stream marker.\n\n--------------------------------------------------------------------------------\n\n\nType Encoding Details#\n\nFixed-Size & Variable-Size Numerics#\n\n * Types: INT8 - UINT64, ULEB128, SLEB128, FLOAT32, FLOAT64\n * Encoding: The header's MMMM bits are unused and should be 0000. The binary\n   data of the specified type immediately follows the header byte.\n\nSHORT#\n\n * Description: Encodes a small, unsigned integer value from 0 to 15.\n * Encoding: The entire field is a single byte.\n   * The TTTT bits identify the type as SHORT.\n   * The MMMM bits contain the actual integer value.\n\nVECTOR#\n\n * Description: Encodes a variable-length array of bytes.\n\n * Encoding: The MMMM bits in the header determine how the size is encoded.\n   \n   * Case 1: Small Vector (0-14 bytes)\n     \n     * The MMMM bits hold the length of the vector (0000 to 1110).\n     * The vector's byte data immediately follows the header.\n   \n   * Case 2: Large Vector (>= 15 bytes)\n     \n     * The MMMM bits are set to 1111.\n     * This signals that a ULEB128-encoded integer representing the vector's\n       true length follows the header.\n     * The vector's byte data follows the ULEB128 length.\n\nEOF#\n\n * Description: Marks the end of the data stream.\n * Encoding: A single byte where the TTTT bits are 1111. The MMMM bits should be\n   0000.\n\n--------------------------------------------------------------------------------\n\n\nRationale#\n\nA new, unified encoding standard is preferable to a heavily patched legacy\nsystem. By replacing CTE with SCTP, we avoid the accumulated complexity of\nmultiple LIPs and introduce a more coherent design. Embedding the specification\ndirectly into the LIP ensures that the proposal and its technical details are\nreviewed and approved as a single, atomic unit.\n\n\nBackwards Compatibility#\n\nThis is a fundamental breaking change. Transactions encoded using the legacy CTE\nformat are not compatible with the new SCTP standard and will be invalid. This\nchange necessitates a coordinated network upgrade. A specific block height or\n\"flag day\" will be designated for the switchover from CTE to SCTP. All node\noperators and developers must upgrade their software to a version that supports\nSCTP before this activation point to remain on the network.\n\n\nSecurity Considerations#\n\nThe security of the LEA protocol now depends entirely on the correctness and\nrobustness of the SCTP specification and its implementations. Implementers must\nbe diligent in creating parsers that are robust against malformed or malicious\ndata to prevent potential vulnerabilities, especially when decoding\nvariable-length structures like VECTOR, ULEB128, and SLEB128. The deprecation of\nCTE removes any security concerns associated with its previous complexity and\npatches.\n\n\nCopyright#\n\nThis LIP is licensed under the MIT License, in alignment with the main LEA\nProject License.","routePath":"/lips/LIP-0006","lang":"","toc":[{"text":"Abstract","id":"abstract","depth":2,"charIndex":231},{"text":"Motivation","id":"motivation","depth":2,"charIndex":662},{"text":"Specification","id":"specification","depth":2,"charIndex":1303},{"text":"Overview","id":"overview","depth":3,"charIndex":1560},{"text":"Header Byte","id":"header-byte","depth":4,"charIndex":1801},{"text":"Type Identifiers","id":"type-identifiers","depth":3,"charIndex":2142},{"text":"Type Encoding Details","id":"type-encoding-details","depth":3,"charIndex":3070},{"text":"Fixed-Size & Variable-Size Numerics","id":"fixed-size--variable-size-numerics","depth":4,"charIndex":3094},{"text":"`SHORT`","id":"short","depth":4,"charIndex":-1},{"text":"`VECTOR`","id":"vector","depth":4,"charIndex":-1},{"text":"`EOF`","id":"eof","depth":4,"charIndex":-1},{"text":"Rationale","id":"rationale","depth":2,"charIndex":4380},{"text":"Backwards Compatibility","id":"backwards-compatibility","depth":2,"charIndex":4750},{"text":"Security Considerations","id":"security-considerations","depth":2,"charIndex":5232},{"text":"Copyright","id":"copyright","depth":2,"charIndex":5732}],"domain":"","frontmatter":{},"version":""},{"id":12,"title":"","content":" * LIP: 7\n * Layer: Application\n * Title: Genesis Transaction Decoder Format\n * Author: Allwin Ketnawang\n * Created: 2025-07-07\n * Requires: 6\n * Status: Draft\n\n\nAbstract#\n\nThis LIP defines the official, standardized binary layout interpreted by the\nGenesis LEA Transaction Decoder.\n\nAs the first canonical decoder in the LEA model, it is based on the Simple\nCompact Transaction Protocol (SCTP) primitives introduced in LIP-6. The format\nfollows a flexible, invocation-based structure, including a unified address\nvector, gas configuration, a sequence of invocation instructions, and a\ndual-signature scheme (Ed25519 and SPHINCS-256s).\n\n\nMotivation#\n\nWhile LIP-6 defines the low-level data primitives for encoding data, it does not\ndefine the high-level structure of a transaction (the \"grammar\"). A standard\ntransaction format is essential for all network participants to interpret,\nvalidate, and process transactions in a uniform way. This proposal provides that\nstandard, detailing the exact order, type, and meaning of each component within\na transaction. It also specifies the precise method for hashing and signing\ntransactions to ensure cryptographic integrity.\n\n\nSpecification#\n\nAll LEA transactions MUST be serialized according to the following structure,\nusing the SCTP encoding types defined in LIP-6. The transaction's total decoded\nsize MUST NOT exceed 1MB.\n\n\nCore Type System#\n\nThe transaction format utilizes a specific subset of the SCTP types:\n\nSCTP TYPE ID   NAME      DESCRIPTION\n8              ULEB128   Unsigned variable-length integer\n13             VECTOR    Raw byte array with a length prefix\n15             EOF       End-of-transaction marker (literal byte: 0x0F)\n\n--------------------------------------------------------------------------------\n\n\nLEA Transaction Format (as interpreted by Genesis Decoder)#\n\nA transaction is a sequence of core fields followed by a variable number of\nInvocation blocks and SignaturePair blocks.\n\nFIELD         TYPE              DESCRIPTION\nversion       ULEB128           Transaction format version. The value MUST be 1.\nsequence      ULEB128           Sender's nonce or sequence number\naddresses     VECTOR            32-byte addresses; signers first, fee payer first\ngasLimit      ULEB128           Max gas units allowed\ngasPrice      ULEB128           Price per gas unit\ninvocations   Invocation[]      One or more invocation instructions\nsignatures    SignaturePair[]   One signature pair per signer\nEOF           Byte (0x0F)       End-of-transaction marker (literal byte)\n\n--------------------------------------------------------------------------------\n\n\nInvocation Block#\n\nFIELD          TYPE      DESCRIPTION\ntargetIndex    ULEB128   Index into the addresses vector (0-based)\ninstructions   VECTOR    Instruction bytecode intended for the target address\n\n--------------------------------------------------------------------------------\n\n\nSignaturePair Block#\n\nFIELD                  TYPE                   DESCRIPTION\ned25519Signature       VECTOR (64 bytes)      Ed25519 signature over the hash\nsphincs256sSignature   VECTOR (29792 bytes)   SPHINCS-256s signature for PQC security\n\n--------------------------------------------------------------------------------\n\n\nNotation Key#\n\n * [] = Repeating block (zero or more)\n * VECTOR = Length-prefixed byte array\n * All field names are case-sensitive and must follow the specified order\n\n--------------------------------------------------------------------------------\n\n\nField Constraints and Rules#\n\n 1. Addresses (addresses):\n    \n    * This field is a single SCTP VECTOR containing all 32-byte addresses\n      involved in the transaction.\n    * The addresses vector MUST be assembled using a deterministic, three-tiered\n      sorting algorithm to ensure a single, canonical representation: a. Group 1\n      (Fee Payer): The address of the fee payer MUST be the first address in the\n      vector (index 0). b. Group 2 (Other Signers): The addresses of all other\n      signers (i.e., the signers from index 1 to N-1) MUST be sorted amongst\n      themselves based on their 32-byte binary lexicographical value. These are\n      appended to the vector immediately after the fee payer. c. Group 3\n      (Non-Signer Addresses): All remaining unique, non-signer addresses MUST\n      also be sorted amongst themselves based on their 32-byte binary\n      lexicographical value. These are appended last.\n    * The addresses vector MUST NOT contain duplicate entries.\n    * The total byte length of the vector MUST be a multiple of 32.\n\n 2. Invocations:\n    \n    * The transaction contains one or more Invocation blocks.\n    * Each Invocation consists of a targetIndex (ULEB128) followed by an\n      instructions field (VECTOR).\n    * The targetIndex MUST be a valid, 0-based index into the addresses vector.\n    * The instructions field contains the application-specific instruction\n      bytecode to be executed in the context of the targeted address.\n\n 3. Signature Set:\n    \n    * The number of SignaturePair blocks implicitly defines the number of signed\n      addresses. If there are N signature pairs, then the first N addresses in\n      the addresses vector are considered signers.\n    * Each SignaturePair corresponds one-to-one with the signers in the\n      addresses vector by index.\n    * Each SignaturePair contains two VECTORs:\n      * ed25519Signature: A 64-byte Ed25519 signature.\n      * sphincs256sSignature: A 29,792-byte SPHINCS-256s signature.\n\n 4. Termination:\n    \n    * Every valid transaction MUST end with a single EOF byte (0x0F).\n    * No other data is permitted after the EOF marker.\n\n--------------------------------------------------------------------------------\n\n\nHashing and Signing Protocol#\n\n * Hashing: The transaction hash is the BLAKE3 digest of the byte stream from\n   the version field up to and including the final byte of the last Invocation\n   block's instructions field. The SignatureSet and the final EOF marker are\n   excluded from the hash.\n * Signing: For every signing address, a corresponding SignaturePair must be\n   provided. The Ed25519 and SPHINCS-256s signatures are calculated over the\n   transaction hash.\n   \n   Signature verification MUST be performed in index order, matching each\n   SignaturePair to the corresponding address in the addresses vector, starting\n   from index 0.\n\n--------------------------------------------------------------------------------\n\n\nRationale#\n\n * Flexible Invocations: The repeating block structure for invocations allows\n   for complex transactions that can interact with multiple programs in a single\n   atomic unit.\n * Implicit Signer Count: Deriving the number of signers from the number of\n   SignaturePair blocks simplifies parsing and removes the need for a separate\n   field to declare the signer count.\n * Unified Address List: A single addresses vector simplifies address management\n   and indexing for invocations.\n * Dual Signatures: Requiring both Ed25519 and SPHINCS-256s (a PQC algorithm)\n   signatures provides both high performance for standard validation and\n   long-term security against quantum attacks.\n * SCTP Base: Building on LIP-6, this ensures that the low-level encoding is\n   consistent with the rest of the protocol.\n\n--------------------------------------------------------------------------------\n\n\nBackwards Compatibility#\n\nThis LIP defines a new, foundational application-layer standard. It does not\nreplace a previously defined transaction format LIP. As such, it does not\nintroduce a backwards compatibility break in the LIP process, but its adoption\nis a mandatory and breaking change for any client or node software wishing to\ninteract with the LEA network, in conjunction with the adoption of LIP-6.\n\n--------------------------------------------------------------------------------\n\n\nSecurity Considerations#\n\n * Hashing Integrity: Validators MUST strictly adhere to the specified hashing\n   protocol. Including any part of the SignatureSet in the hash would invalidate\n   all signatures.\n * Signature Verification: For each SignaturePair, both the Ed25519 and\n   SPHINCS-256s signatures must be successfully verified against the transaction\n   hash using the public key of the corresponding signing address. A failure in\n   either verification invalidates the transaction.\n * Index-out-of-Bounds: Parsers MUST validate that each targetIndex in an\n   invocation is a valid index within the addresses vector. An invalid index\n   must cause the transaction to be rejected.\n * Vector Length Validation: Parsers MUST validate that the addresses vector\n   length is a multiple of 32 and that the signature vectors have the correct\n   fixed lengths (64 and 29792). Failure to do so could lead to buffer overflows\n   or incorrect data interpretation.\n * Fee Payer: The first entry in the addresses vector is the fee payer. Logic\n   for deducting fees must correctly and exclusively identify this address.\n\n--------------------------------------------------------------------------------\n\n\nCopyright#\n\nThis LIP is licensed under the MIT License, in alignment with the main LEA\nProject License.","routePath":"/lips/LIP-0007","lang":"","toc":[{"text":"Abstract","id":"abstract","depth":2,"charIndex":161},{"text":"Motivation","id":"motivation","depth":2,"charIndex":637},{"text":"Specification","id":"specification","depth":2,"charIndex":1170},{"text":"Core Type System","id":"core-type-system","depth":3,"charIndex":1372},{"text":"LEA Transaction Format (as interpreted by Genesis Decoder)","id":"lea-transaction-format-as-interpreted-by-genesis-decoder","depth":3,"charIndex":1773},{"text":"Invocation Block","id":"invocation-block","depth":3,"charIndex":2620},{"text":"SignaturePair Block","id":"signaturepair-block","depth":3,"charIndex":2905},{"text":"Notation Key","id":"notation-key","depth":3,"charIndex":3233},{"text":"Field Constraints and Rules","id":"field-constraints-and-rules","depth":3,"charIndex":3484},{"text":"Hashing and Signing Protocol","id":"hashing-and-signing-protocol","depth":3,"charIndex":5701},{"text":"Rationale","id":"rationale","depth":2,"charIndex":6427},{"text":"Backwards Compatibility","id":"backwards-compatibility","depth":2,"charIndex":7325},{"text":"Security Considerations","id":"security-considerations","depth":2,"charIndex":7817},{"text":"Copyright","id":"copyright","depth":2,"charIndex":9015}],"domain":"","frontmatter":{},"version":""},{"id":13,"title":"","content":" * LIP: 8\n * Layer: Application\n * Title: VM's Supported Features\n * Author: Allwin Ketnawang\n * Created: 2025-07-11\n * Status: Draft\n\n\nAbstract#\n\nThis LIP provides a technical explanation of the supported and unsupported\nWebAssembly (WASM) features in the LEA Virtual Machine. It clarifies which\nfeatures are enabled to ensure deterministic execution and high security, and\nwhich are disabled to prevent non-determinism and potential consensus failures.\nThis document serves as a guide for developers building applications on the LEA\nplatform.\n\n\nMotivation#\n\nThe LEA WebAssembly (WASM) Virtual Machine is a specialized runtime designed for\nenvironments that demand high security and deterministic execution, LEA VM's\nfeature set is tailored to ensure that every operation produces an identical\nresult across all nodes in a network, which is critical for achieving consensus.\nA clear specification of supported features is necessary for developers to build\ncompatible and secure smart contracts.\n\n\nSpecification#\n\nBased on the requirements for determinism and security, the LEA VM supports a\ncore set of stable, deterministic WebAssembly features while actively disabling\nexperimental or non-deterministic ones.\n\n\nSupported and Recommended Features#\n\nThe LEA VM is optimized for safety and predictability. The following WebAssembly\nfeatures are considered safe and are supported:\n\n * -mbulk-memory: This feature is fully supported. It provides highly efficient\n   methods for managing and manipulating large blocks of memory, such as\n   memory.copy and memory.fill. These operations are deterministic and\n   significantly improve performance for memory-intensive tasks without\n   compromising consensus.\n\n * -msign-ext: Support for sign-extension operations is included. This allows\n   for the correct and predictable conversion between integer types of different\n   sizes (e.g., from an 8-bit integer to a 32-bit integer), which is a\n   fundamental and stable part of the WebAssembly specification.\n\n * -mmultivalue: The LEA VM supports returning multiple values from a single\n   function. This is a widely adopted and stable feature that helps developers\n   write cleaner and more efficient code. For example, a function in Rust\n   returning a tuple (i32, i32) will compile correctly. To ensure this works\n   when compiling with Clang-based tools (like rustc), the compiler must be\n   configured with the appropriate ABI flags (-Xclang -target-abi -Xclang\n   experimental-mv).\n\n\nUnsupported and Discouraged Features#\n\nTo maintain determinism and security, the LEA VM explicitly avoids features that\ncould introduce unpredictable behavior or security risks. The following are not\nsupported:\n\n * -msimd128: SIMD (Single Instruction, Multiple Data) operations are disabled.\n   While powerful for multimedia and scientific computing, their results can\n   vary subtly across different CPU architectures, making them unsuitable for\n   consensus-critical applications.\n\n * -matomics: Threading and atomic operations are not supported. Blockchain\n   smart contracts are single-threaded by design. Introducing atomics or shared\n   memory would break this model and introduce significant complexity and\n   consensus risks.\n\n * -mnontrapping-fptoint: This feature, which prevents crashes on invalid\n   floating-point to integer conversions, is disabled. In a deterministic\n   system, such invalid operations must be handled as explicit, predictable\n   traps (errors) rather than producing a default value, which could lead to\n   state divergence.\n\n * Experimental Proposals: Any features that are still experimental or subject\n   to change are not supported. This includes:\n   \n   * -mreference-types: Introduces garbage collection and complex reference\n     handling, which are not yet considered deterministic or secure enough for\n     blockchain VMs.\n   * -mtail-call: A proposal for optimizing function calls that has unclear and\n     potentially non-deterministic behavior regarding the call stack.\n\n\nRationale#\n\nThe selection of WASM features is strictly guided by the core requirements of a\nblockchain environment: determinism, security, and consensus. The enabled\nfeatures (bulk-memory, sign-ext, multivalue) are all stable, well-defined, and\nguaranteed to produce identical results on any compliant hardware. Features like\nSIMD and atomics are disabled because they can introduce implementation-defined\nbehavior or break the single-threaded execution model, which would make it\nimpossible to guarantee consensus. By restricting the VM to a core, stable, and\ndeterministic subset of WebAssembly, the LEA platform ensures a robust and\nsecure foundation for smart contracts.\n\n\nBackwards Compatibility#\n\nThis LIP is purely informational and defines the capabilities of the LEA VM. It\ndoes not introduce any backwards compatibility issues with the LEA protocol\nitself.\n\n\nSecurity Considerations#\n\nThe feature set described in this LIP is fundamental to the security model of\nthe LEA platform. By disabling non-deterministic and experimental features, the\nVM reduces the attack surface and prevents a class of vulnerabilities related to\nstate divergence and consensus splits. Adherence to this specified feature set\nis critical for maintaining the security and integrity of all applications\nrunning on the LEA network.\n\n\nCopyright#\n\nThis LIP is licensed under the MIT License, in alignment with the main LEA\nProject License.","routePath":"/lips/LIP-0008","lang":"","toc":[{"text":"Abstract","id":"abstract","depth":2,"charIndex":135},{"text":"Motivation","id":"motivation","depth":2,"charIndex":546},{"text":"Specification","id":"specification","depth":2,"charIndex":997},{"text":"Supported and Recommended Features","id":"supported-and-recommended-features","depth":3,"charIndex":1213},{"text":"Unsupported and Discouraged Features","id":"unsupported-and-discouraged-features","depth":3,"charIndex":2480},{"text":"Rationale","id":"rationale","depth":2,"charIndex":3996},{"text":"Backwards Compatibility","id":"backwards-compatibility","depth":2,"charIndex":4673},{"text":"Security Considerations","id":"security-considerations","depth":2,"charIndex":4865},{"text":"Copyright","id":"copyright","depth":2,"charIndex":5314}],"domain":"","frontmatter":{},"version":""},{"id":14,"title":"","content":" * LIP: 9\n * Layer: Consensus\n * Title: Programmable Transaction Format\n * Author: Allwin Ketnawang\n * Created: 2025-07-12\n * Status: Draft\n\n\nAbstract#\n\nThis LIP proposes a universal transaction format for the LEA protocol. The\nformat consists of a minimal, two-part structure: a DecoderID and a Payload. The\nDecoderID is a 32-byte identifier for an on-chain contract responsible for\ninterpreting the transaction. The Payload is an opaque byte stream passed to\nthis contract. This design delegates all transaction validation, serialization,\nand execution logic to the contract layer, making the base protocol itself\nsimpler and more extensible.\n\n\nMotivation#\n\nTraditional blockchain protocols enforce a single, rigid transaction structure.\nThis creates significant friction when introducing new features, such as novel\nsignature schemes, privacy-preserving technologies, or account abstraction\nlogic. Implementing such upgrades typically requires a network-wide consensus\nchange (hard fork), which is a slow, contentious, and complex process.\n\nThe motivation for this proposal is to create a flexible and future-proof\nfoundation for the protocol. By abstracting transaction interpretation away from\nthe base consensus rules, the network can adopt new functionalities dynamically,\nwithout requiring core protocol modifications. This shifts the responsibility\nfor innovation to the execution layer, allowing for faster, permissionless\nevolution.\n\n\nSpecification#\n\nThe base protocol shall recognize a single transaction structure, referred to as\nthe \"Transaction Envelope.\"\n\n 1. Transaction Envelope Definition: The Transaction Envelope is the raw byte\n    array submitted to the network for processing. It is composed of two\n    distinct fields:\n    \n    * DecoderID [bytes 32]: The first 32 bytes of the envelope. This field\n      contains the address of a smart contract, hereafter referred to as the\n      \"Decoder.\"\n    * Payload [bytes N]: All bytes of the envelope following the DecoderID. The\n      protocol treats this field as an opaque byte stream.\n\n 2. Base Protocol Execution Rule: The consensus layer will enforce a single,\n    immutable rule for initiating transaction processing:\n    \n    a. Upon receiving a Transaction Envelope, the node reads the first 32 bytes\n    to identify the DecoderID. b. The node invokes the contract located at the\n    DecoderID address. c. The node passes the Payload to the Decoder contract\n    for all subsequent processing.\n\n 3. Decoder Responsibilities: The Decoder contract is responsible for all logic\n    related to the transaction, including, but not limited to:\n    \n    * Parsing the Payload.\n    * Validating signatures and authorizing the transaction.\n    * Implementing replay protection (e.g., via a nonce).\n    * Defining and processing fee payments.\n    * Executing the state transition.\n\n\nRationale#\n\nThe design is based on the principle of a minimal, robust core protocol with\nmaximal flexibility at the edges.\n\n * Forward Compatibility: This is the primary rationale. New cryptographic\n   standards (e.g., post-quantum signatures) or transaction features (e.g.,\n   calldata compression, ZK-proof verification) can be introduced by deploying a\n   new Decoder contract. This avoids the need for hard forks for a wide class of\n   upgrades.\n * Native Account Abstraction: This model provides account abstraction at the\n   protocol's most fundamental level. The logic for what constitutes a valid\n   transaction (e.g., multi-sig, social recovery, fee payment in arbitrary\n   tokens) is not defined by the protocol but by the Decoder, which is chosen by\n   the user or wallet.\n * Architectural Simplicity: By delegating complexity to the execution layer,\n   the consensus engine is simplified significantly. Its sole responsibility is\n   to dispatch the payload to the correct interpreter. This reduces the surface\n   area for potential consensus-level bugs. This layered architecture is\n   analogous to the Internet Protocol (IP), where the core network layer is\n   responsible for routing packets, while higher-level protocols (TCP, HTTP)\n   handle interpretation and structure.\n\n\nBackwards Compatibility#\n\nThis LIP defines the foundational transaction format for the LEA protocol. As\nsuch, it does not have backwards compatibility considerations with a prior\nstate. It establishes the framework upon which all future transaction types will\nbe built.\n\n\nSecurity Considerations#\n\nThe security model is shifted from the protocol to the execution layer.\n\n * Decoder Security: The integrity and security of any given transaction are\n   entirely dependent on the implementation of its specified Decoder contract.\n   Users must trust the Decoders they use. A buggy or malicious Decoder could\n   result in a permanent loss of funds.\n * Gas Metering: To prevent Denial-of-Service attacks from computationally\n   intensive or non-terminating Decoders, their execution must be strictly\n   metered (i.e., via a gas mechanism).\n * Replay Protection: The base protocol does not provide replay protection. Each\n   Decoder must implement its own nonce or other replay prevention mechanism.\n   Failure to do so would make transactions vulnerable to replay attacks.\n\n\nCopyright#\n\nThis LIP is licensed under the MIT License.","routePath":"/lips/LIP-0009","lang":"","toc":[{"text":"Abstract","id":"abstract","depth":2,"charIndex":141},{"text":"Motivation","id":"motivation","depth":2,"charIndex":646},{"text":"Specification","id":"specification","depth":2,"charIndex":1445},{"text":"Rationale","id":"rationale","depth":2,"charIndex":2848},{"text":"Backwards Compatibility","id":"backwards-compatibility","depth":2,"charIndex":4138},{"text":"Security Considerations","id":"security-considerations","depth":2,"charIndex":4410},{"text":"Copyright","id":"copyright","depth":2,"charIndex":5208}],"domain":"","frontmatter":{},"version":""},{"id":15,"title":"","content":" * LIP: 10\n * Layer: Application\n * Title: Transaction Manifest (LTM)\n * Author: Allwin Ketnawang\n * Created: 2025-07-15\n * Requires: 7\n * Status: Proposed\n\n\nAbstract#\n\nThis LIP proposes the LEA Transaction Manifest (LTM), a standardized,\ndeclarative JSON format for defining LEA transactions. The LTM schema is\ndesigned to abstract away the complexities of binary serialization, allowing\ndevelopers and users to define complex transactions in a human-readable and\nreusable manner. It provides a robust system for sourcing data dynamically from\nthe local file system and other data structures. The primary goal of LTM is to\nmake transaction creation simpler, safer, and more transparent, separating the\ndefinition of a transaction's data from the logic of its binary encoding.\n\n\nMotivation#\n\nThe process of creating a valid LEA transaction, as defined in LIP-7, requires\nprecise binary encoding using the Simple Compact Transaction Protocol (SCTP).\nConstructing this binary stream programmatically is a low-level task that is\nverbose, error-prone, and requires custom scripting for each new type of\ntransaction. This approach tightly couples the transaction's data with the\napplication logic, making it difficult to manage, reuse, or audit transaction\ndefinitions.\n\nThe LEA Transaction Manifest (LTM) introduces a declarative layer that solves\nthis problem. By defining a transaction in a structured JSON format, users can\nclearly specify all its components (such as signers, gas parameters, and\ncontract invocations) without writing any encoding logic. The LTM format is\ndesigned to be processed by a build tool that handles all the underlying\ncomplexities of data resolution, SCTP encoding, hashing, and signing. This\nseparation of concerns dramatically simplifies the user experience, reduces the\nrisk of malformed transactions, and promotes the creation of reusable\ntransaction templates.\n\n\nSpecification#\n\nA LEA Transaction Manifest is a JSON file that adheres to the following\nstructure. The file must be parsed by a tool that can safely handle large\nintegers to prevent precision loss.\n\n\n1. Top-Level Structure#\n\nThe LTM is a single JSON object with the following root fields. The version\nfield, specified as the first field in the LIP-7 binary format, is intentionally\nexcluded. The build tool that processes the manifest is responsible for\nautomatically prepending the protocol version (1) during binary serialization.\n\nFIELD         TYPE               REQUIRED   DESCRIPTION\nsequence      Number or String   Yes        The sequence number (nonce) for the fee-paying signer.\nfeePayer      String             Yes        The name of the signer who will pay the transaction fees.\n                                            Must match a key in the signers object.\ngasLimit      Number or String   Yes        The maximum gas units the transaction can consume.\ngasPrice      Number or String   Yes        The price per gas unit.\noutputFile    String             No         The file path where the final binary transaction will be\n                                            written. If omitted when using the CLI, the binary output is\n                                            written to stdout. This field is ignored when used as a\n                                            module.\nconstants     Object             No         An object defining reusable values that can be referenced\n                                            elsewhere in the manifest.\nsigners       Object             Yes        An object defining the one or more signers for the\n                                            transaction.\ninvocations   Array              Yes        An array of one or more invocation objects.\n\n\n2. signers Object#\n\nThe signers object contains one or more key-value pairs, where each key is a\nunique, user-defined name for the signer (e.g., mainAccount, alice). This name\nis used to reference the signer in the feePayer field and in $signer()\nplaceholders.\n\nThe value for each signer can be one of two types:\n\n * File Path (String): A string containing the relative path to a LEA Keyset\n   file. The file MUST conform to the format defined in LIP-12: LEA Keyset File\n   Format.\n * Keyset Object (Array): A direct JSON array conforming to the LIP-12 keyset\n   structure. This is primarily for programmatic use when the LTM is used as a\n   library/module.\n\nA build tool resolves these values to load the cryptographic keys needed for\nsigning.\n\nExample:\n\n\n\n\n3. constants Object#\n\nThis optional top-level object allows you to define key-value pairs for reusable\nvalues. These constants can be referenced in other parts of the manifest using\nthe $const() placeholder. This is useful for reducing repetition and improving\nmaintainability.\n\nExample:\n\n\n\n\n4. invocations Array#\n\nThe invocations array contains one or more objects, each representing a single\ncall to a smart contract.\n\nFIELD           TYPE     REQUIRED   DESCRIPTION\ntargetAddress   String   Yes        The 32-byte hex address of the target contract. Can be a\n                                    literal or use a placeholder.\ninstructions    Array    Yes        An array defining the instruction payload to be sent to the\n                                    target.\n\n\n5. Address Vector and Signature Assembly#\n\nA compliant LTM build tool MUST follow a strict, deterministic algorithm to\nassemble the final addresses vector and signatures list for the binary\ntransaction defined in LIP-7.\n\nThe following algorithm MUST be used:\n\n 1. Resolve Placeholders and Collect Addresses: a. A build tool MUST first\n    perform a full resolution of all placeholders in the manifest, including\n    chained placeholders (e.g., $addr($const(user))). It MUST detect and fail if\n    a circular dependency is found. b. During or after resolution, create a set\n    to store all unique 32-byte addresses required for the transaction. This\n    automatically handles de-duplication as required by LIP-7. c. Add the\n    addresses of all signers defined in the signers object to the set. d. Add\n    the fully-resolved targetAddress from each object in the invocations array\n    to the set. e. Add the fully-resolved address from any $addr() placeholder\n    to the set.\n 2. Identify Fee Payer: The signer name specified in the feePayer field is the\n    fee payer.\n 3. Build the Final addresses Vector: The final vector is assembled using a\n    deterministic, three-tiered sorting algorithm to ensure stability and\n    predictability. a. Group 1 (Fee Payer): The fee payer's address is the first\n    address in the vector (index 0). b. Group 2 (Other Signers): The addresses\n    of all other signers (excluding the fee payer) are sorted amongst themselves\n    based on their 32-byte binary lexicographical value. These are appended to\n    the vector after the fee payer. c. Group 3 (Non-Signer Addresses): All\n    remaining unique addresses from the set (i.e., non-signers) are sorted\n    amongst themselves based on their 32-byte binary lexicographical value.\n    These are appended last.\n 4. Resolve $addr() to Index: After the final addresses vector is constructed,\n    replace every $addr() placeholder string with the final numeric index of its\n    corresponding address in the vector. This final number is then encoded\n    according to the instruction's integer type.\n\nThe resulting ordered list is the final addresses vector for the transaction.\nThe signatures in the binary output MUST correspond to the signer addresses in\nthe exact same order as they appear in the final vector (fee payer first, then\nthe other signers sorted by their binary address).\n\n\n6. instructions Array#\n\nThis array defines the sequence of data fields that constitute the instruction\npayload. Each element in the array is an object with a single key, where the key\nis the SCTP type (e.g., vector, uleb) and the value is the data to be encoded.\n\n\n7. Placeholder Syntax for Dynamic Data#\n\nTo enable dynamic data sourcing, LTM values can use a function-like placeholder\nsyntax: $<source>(<value>). Placeholders can be chained (nested), and a build\ntool MUST support this.\n\nPLACEHOLDER SYNTAX             EXAMPLE                              DESCRIPTION\n$const(<key>)                  \"$const(tokenProgram)\"               Retrieves a value from the constants object.\n$signer(<name>.<key>)          \"$signer(main.address)\"              Retrieves a derived value from a named signer. Valid keys\n                                                                    are ed25519Pk, sphincsPk, and address.\n$addr(<source>[#<fmt>])        \"$addr($const(user))\"                A special placeholder for integer types (uleb, uint8, etc.)\n                                                                    that resolves an address source to its final index in the\n                                                                    transaction's address vector. The <source> can be a literal\n                                                                    string or another placeholder. The optional fmt (hex or\n                                                                    bech32m) specifies how to interpret the resolved source\n                                                                    string. Defaults to bech32m.\n$file(<path>)                  \"$file(./payload.bin)\"               Reads the raw binary content of a file. The value is a byte\n                                                                    array.\n$hex(<hex_string>)             \"$hex(deadbeef0123)\"                 Interprets a literal string as a hexadecimal byte sequence.\n                                                                    The value is a byte array.\n$json(<path>#<path>[#<fmt>])   \"$json(./cfg.json#profile.id#hex)\"   Parses a JSON file and extracts a value using a\n                                                                    dot-separated path. The path is a dot-separated sequence of\n                                                                    keys used to extract a value from a nested JSON object\n                                                                    (e.g., data.user.id). This simple pathing does not support\n                                                                    array indexing or advanced query expressions. If the\n                                                                    extracted value is a string and a fmt (hex or bech32m) is\n                                                                    provided, it is decoded into a byte array. Otherwise, the\n                                                                    raw JSON value (string, number) is used.\n\nText-to-Binary Decoding#\n\nFor placeholders like $json that produce string outputs, the #hex and #bech32m\nformat specifiers can be used to decode the final string into a raw byte array.\nThis is required when the instruction field is a vector.\n\n\n8. General Schema Rules#\n\nField Naming and Case Sensitivity#\n\nAll field names defined in this specification are case-sensitive and MUST be\nwritten in camelCase. An LTM parsing tool must reject any manifest that uses a\ndifferent case or format (e.g., snake_case or kebab-case) for official field\nnames.\n\nComments#\n\nJSON does not natively support comments. To allow for inline documentation, any\nJSON object within an LTM file may include a field with the key comment. An LTM\ntool MUST completely ignore this field and its value during processing.\n\nExample:\n\n\n\n\n9. Data Type Handling#\n\n * Literals: Values without placeholders are treated as literals (e.g., 123,\n   \"hello\").\n * Large Integers: The JSON specification allows for numbers of arbitrary\n   precision. However, many standard parsers (like JavaScript's native\n   JSON.parse()) will truncate large integer values, leading to silent data\n   corruption. Therefore, it is a strict requirement that any compliant LTM\n   implementation MUST use a parser that preserves the full precision of all\n   numeric literals, converting them to a BigInt or an equivalent lossless type.\n   While a compliant tool must handle unquoted large numbers safely, providing\n   them as strings (e.g., \"18446744073709551615\") remains a recommended best\n   practice to ensure maximum compatibility across different platforms and\n   tools.\n * Programmable Use: When used as a library, an LTM build tool should provide\n   maximum flexibility by accepting direct JavaScript types for instruction\n   fields. This includes Uint8Array for vector types, BigInt for large integer\n   types (e.g., uint64, sleb), and standard Number for smaller integer and float\n   types (e.g., uint32, float64). The tool is responsible for validating that a\n   provided Number is within the valid and safe range for its target SCTP type.\n\n\nFull Example#\n\n\n\n\nRationale#\n\nThe design of the LTM is guided by the principles of clarity, safety, and\nflexibility.\n\n * JSON as a Base: JSON is ubiquitous, human-readable, and supported by\n   virtually all programming languages, making it an ideal foundation.\n * Declarative Approach: By defining what the transaction should contain rather\n   than how to build it, the manifest separates concerns. This simplifies the\n   user's task and allows the underlying build tool to be optimized\n   independently.\n * Placeholder System: A simple, consistent placeholder syntax ($source(...))\n   provides powerful and explicit data sourcing capabilities. This avoids the\n   need for complex templating languages while enabling composition from files\n   and other data sources.\n * Single-Key Instruction Objects: Using { \"type\": \"value\" } for instructions is\n   concise and less verbose than { \"type\": \"type\", \"value\": \"value\" }, making\n   the manifest cleaner and easier to read.\n\n\nTooling Recommendations#\n\nTo improve the developer experience and provide better debugging capabilities,\nthis specification recommends that a compliant LTM build tool implement the\nfollowing features.\n\n * Dry Run / Debug Mode: A tool SHOULD provide a \"dry run\" or \"debug\" flag\n   (e.g., --resolve-only). When enabled, this mode would perform all placeholder\n   resolution and validation steps and then output the fully resolved JSON\n   manifest, with all placeholders replaced by their final values. It would stop\n   before performing binary serialization or signing. This provides an\n   invaluable mechanism for developers to inspect the final, resolved data and\n   verify its correctness before creating the transaction.\n\n\nBackwards Compatibility#\n\nThe LEA Transaction Manifest is a new, additive standard for tooling and\napplication-layer development. It does not propose any changes to the underlying\ntransaction format defined in LIP-7 or any other core protocol rule. Therefore,\nit introduces no backwards compatibility issues.\n\n\nSecurity Considerations#\n\nA compliant LTM build tool MUST be designed with a \"secure by default\"\nphilosophy, protecting users from potentially malicious manifests unless they\nexplicitly opt into dangerous functionality.\n\n * File System Access: The $file and $json placeholders can read from the file\n   system. To prevent unauthorized access, a build tool MUST enforce the\n   following rules by default:\n   * All file paths MUST resolve to a location within the same directory as the\n     manifest file, or a subdirectory thereof. Path traversal (../) is\n     forbidden.\n   * Symbolic links MUST NOT be followed.\n   * Broader file system access should only be possible via an explicit flag\n     (e.g., --enable-unsafe-filesystem-access).\n * Resource Limits (Anti-DoS): To prevent Denial-of-Service attacks, a build\n   tool MUST enforce reasonable resource limits by default.\n   * File Size: The maximum size for files read via $file or $json should be\n     limited (e.g., 1 MB).\n   * Nesting Depth: The maximum nesting depth for placeholders should be limited\n     (e.g., 3 levels).\n   * These limits should only be removable with an explicit flag (e.g.,\n     --enable-unsafe-limits).\n * Safe JSON Parsing: Implementations of LTM parsers MUST use a library that can\n   safely handle large integers (e.g., json-bigint for Node.js) to prevent\n   silent precision loss on 64-bit numbers. Parsers MUST also operate in a\n   strict mode that rejects duplicate keys to prevent malicious or accidental\n   parameter overrides.\n * Circular Dependencies: A compliant LTM build tool MUST implement a mechanism\n   to detect and reject manifests containing circular placeholder references\n   (e.g., \"$const(a)\" where a references \"$const(b)\" and b references\n   \"$const(a)\"). Failure to do so can result in non-terminating loops and\n   denial-of-service vulnerabilities.\n\n\nCopyright#\n\nThis LIP is licensed under the MIT License.","routePath":"/lips/LIP-0010","lang":"","toc":[{"text":"Abstract","id":"abstract","depth":2,"charIndex":157},{"text":"Motivation","id":"motivation","depth":2,"charIndex":778},{"text":"Specification","id":"specification","depth":2,"charIndex":1894},{"text":"1. Top-Level Structure","id":"1-top-level-structure","depth":3,"charIndex":2094},{"text":"2. `signers` Object","id":"2-signers-object","depth":3,"charIndex":-1},{"text":"3. `constants` Object","id":"3-constants-object","depth":3,"charIndex":-1},{"text":"4. `invocations` Array","id":"4-invocations-array","depth":3,"charIndex":-1},{"text":"5. Address Vector and Signature Assembly","id":"5-address-vector-and-signature-assembly","depth":3,"charIndex":5234},{"text":"6. `instructions` Array","id":"6-instructions-array","depth":3,"charIndex":-1},{"text":"7. Placeholder Syntax for Dynamic Data","id":"7-placeholder-syntax-for-dynamic-data","depth":3,"charIndex":7868},{"text":"Text-to-Binary Decoding","id":"text-to-binary-decoding","depth":4,"charIndex":10648},{"text":"8. General Schema Rules","id":"8-general-schema-rules","depth":3,"charIndex":10892},{"text":"Field Naming and Case Sensitivity","id":"field-naming-and-case-sensitivity","depth":4,"charIndex":10918},{"text":"Comments","id":"comments","depth":4,"charIndex":11195},{"text":"9. Data Type Handling","id":"9-data-type-handling","depth":3,"charIndex":11452},{"text":"Full Example","id":"full-example","depth":3,"charIndex":12738},{"text":"Rationale","id":"rationale","depth":2,"charIndex":12756},{"text":"Tooling Recommendations","id":"tooling-recommendations","depth":2,"charIndex":13710},{"text":"Backwards Compatibility","id":"backwards-compatibility","depth":2,"charIndex":14435},{"text":"Security Considerations","id":"security-considerations","depth":2,"charIndex":14746},{"text":"Copyright","id":"copyright","depth":2,"charIndex":16605}],"domain":"","frontmatter":{},"version":""},{"id":16,"title":"","content":" * LIP: 11\n * Layer: Application\n * Title: Public Key Module Interface (LEA-PKMI)\n * Author: Allwin Ketnawang\n * Created: 2025-07-16\n * Status: Proposed\n\n\nAbstract#\n\nThis LIP defines a standard interface for WebAssembly (WASM) modules that\nprovide public-key cryptography functions. The LEA Public Key Module Interface\n(LEA-PKMI) specifies a set of required imports and exports that enable seamless\nintegration of cryptographic modules for operations like key generation,\nsigning, and verification within the LEA ecosystem. This standardization\npromotes interoperability, simplifies development, and allows for modular\nreplacement of cryptographic implementations.\n\n\nMotivation#\n\nAs the LEA ecosystem grows, there is a need for a standardized way to perform\npublic-key cryptography across different applications and environments. Without\na defined interface, developers must write custom \"glue code\" for each specific\ncryptographic library, leading to duplicated effort, increased complexity, and a\nhigher risk of implementation errors.\n\nThe LEA-PKMI provides a clear, minimal, and efficient contract between a host\nenvironment and a WASM-based cryptographic module. This allows developers to\neasily swap different modules (e.g., switching from an Ed25519 module to a\ndifferent signature scheme) without changing the host application's code,\nfostering a more flexible and secure development environment.\n\n\nSpecification#\n\nAny WASM module compliant with LEA-PKMI MUST implement the following interface.\n\n\n1. Imports#\n\nThe module MUST import the following functions from the host environment under\nthe env namespace.\n\n * __lea_abort(line: i32)\n   \n   * Description: Called by the module to signal a fatal, unrecoverable error.\n   * Parameters:\n     * line: A 32-bit integer representing the source code line number where the\n       error occurred.\n   * Host Action: The host must terminate the execution environment.\n\n * __lea_randombytes(ptr: i32, len: i32)\n   \n   * Description: Called by the module to request cryptographically secure\n     random data.\n   * Parameters:\n     * ptr: A 32-bit integer representing the memory address where the host\n       should write the random data.\n     * len: A 32-bit integer specifying the number of bytes to write.\n   * Host Action: The host must fill the module's linear memory at ptr with len\n     bytes of secure random data.\n\n\n2. Exports#\n\nThe module MUST export the following memory and functions.\n\n2.1. Memory#\n\n * memory: WebAssembly.Memory\n   * Description: The module's linear memory. The host uses this to write input\n     data (e.g., messages) and read output data (e.g., keys, signatures).\n\n2.2. Allocator Functions#\n\n * __lea_malloc(size: i32): i32\n   \n   * Description: Allocates a memory block of size bytes.\n   * Returns: A pointer to the start of the allocated block.\n\n * __lea_allocator_reset()\n   \n   * Description: Resets the module's internal allocator, invalidating all\n     pointers.\n\n2.3. Constant Functions#\n\n * pk_bytes(): i32\n   \n   * Returns: The required size in bytes for a public key.\n\n * sk_bytes(): i32\n   \n   * Returns: The required size in bytes for a secret key.\n\n * signature_bytes(): i32\n   \n   * Returns: The required size in bytes for a signature.\n\n2.4. Cryptographic Functions#\n\nThese functions MUST return 0 on success and a non-zero integer on failure.\n\n * keygen(pk_ptr: i32, sk_ptr: i32): i32\n   \n   * Description: Generates a new key pair.\n   * Parameters:\n     * pk_ptr: Pointer to an allocated block for the public key.\n     * sk_ptr: Pointer to an allocated block for the secret key.\n\n * sign(sig_ptr: i32, msg_ptr: i32, msg_len: i32, sk_ptr: i32): i32\n   \n   * Description: Signs a message with a secret key.\n   * Parameters:\n     * sig_ptr: Pointer to an allocated block for the output signature.\n     * msg_ptr: Pointer to the message to be signed.\n     * msg_len: The length of the message.\n     * sk_ptr: Pointer to the secret key.\n\n * verify(sig_ptr: i32, msg_ptr: i32, msg_len: i32, pk_ptr: i32): i32\n   \n   * Description: Verifies a signature against a message and public key.\n   * Parameters:\n     * sig_ptr: Pointer to the signature to verify.\n     * msg_ptr: Pointer to the original message.\n     * msg_len: The length of the message.\n     * pk_ptr: Pointer to the public key.\n\n\nRationale#\n\nThe design of the LEA-PKMI prioritizes simplicity, security, and performance.\n\n * Minimalism: The interface exposes only the essential functions required for\n   public-key cryptography. This simplifies host-side integration by providing a\n   clear and focused set of operations.\n * Language Agnostic: By using only 32-bit integer types (i32), the interface\n   remains compatible with any host language that can interact with WebAssembly,\n   avoiding complexities of higher-level data types.\n * Explicit Memory Management: The host controls memory allocation via\n   __lea_malloc and can reset the state with __lea_allocator_reset. This simple\n   model avoids the need for complex memory management or garbage collection\n   schemes across the WASM boundary.\n * Host-Provided Randomness: The module relies on the host for random data via\n   __lea_randombytes. This is a critical security decision, as generating secure\n   randomness is a responsibility best handled by the host environment, which\n   has direct access to system-level entropy sources.\n\n\nBackwards Compatibility#\n\nThis LIP introduces a new standard and does not break any existing protocols. It\nis intended for new cryptographic modules developed for the LEA ecosystem.\nExisting modules would need to be updated to comply with this interface.\n\n\nSecurity Considerations#\n\n * Host Responsibilities: The host environment is responsible for providing a\n   cryptographically secure random number generator (CSPRNG) for the\n   __lea_randombytes import. A weak or predictable source of randomness will\n   compromise all cryptographic operations. The host must also handle the\n   __lea_abort call by safely terminating the process to prevent further\n   execution in a potentially corrupt state.\n * Module Responsibilities: The WASM module is a security-critical component. It\n   must be carefully implemented and audited to ensure it is free of\n   vulnerabilities. The module should perform all necessary input validation and\n   operate with constant-time algorithms where appropriate to prevent\n   side-channel attacks.\n * Interface Security: The interface itself is designed to be simple, reducing\n   the potential for misuse. By passing data via pointers, it avoids copying\n   large amounts of data across the WASM boundary, which can be a source of both\n   performance issues and vulnerabilities.\n\n\nCopyright#\n\nThis LIP is licensed under the MIT License.","routePath":"/lips/LIP-0011","lang":"","toc":[{"text":"Abstract","id":"abstract","depth":2,"charIndex":154},{"text":"Motivation","id":"motivation","depth":2,"charIndex":666},{"text":"Specification","id":"specification","depth":2,"charIndex":1405},{"text":"1. Imports","id":"1-imports","depth":3,"charIndex":1503},{"text":"2. Exports","id":"2-exports","depth":3,"charIndex":2369},{"text":"2.1. Memory","id":"21-memory","depth":4,"charIndex":2442},{"text":"2.2. Allocator Functions","id":"22-allocator-functions","depth":4,"charIndex":2641},{"text":"2.3. Constant Functions","id":"23-constant-functions","depth":4,"charIndex":2946},{"text":"2.4. Cryptographic Functions","id":"24-cryptographic-functions","depth":4,"charIndex":3227},{"text":"Rationale","id":"rationale","depth":2,"charIndex":4277},{"text":"Backwards Compatibility","id":"backwards-compatibility","depth":2,"charIndex":5339},{"text":"Security Considerations","id":"security-considerations","depth":2,"charIndex":5596},{"text":"Copyright","id":"copyright","depth":2,"charIndex":6646}],"domain":"","frontmatter":{},"version":""},{"id":17,"title":"","content":" * LIP: 12\n * Layer: Application\n * Title: Keyset File Format\n * Author: Allwin Ketnawang\n * Created: 2025-07-16\n * Status: Proposed\n\n\nAbstract#\n\nThis LIP defines a standard JSON-based file format for storing the cryptographic\nkeys required for a LEA account. The format encapsulates the Ed25519 secret key\nand the SPHINCS+ secret and public keys into a structured, compact, and\nmachine-readable file. The primary goal is to ensure interoperability between\ndifferent wallets, tools, and applications within the LEA ecosystem.\n\n\nMotivation#\n\nTo interact with the Lea network, a user must manage a set of cryptographic\nkeys. Without a standardized format for storing these keys, each application\n(e.g., CLI tools, wallets, libraries) would be forced to implement its own\nproprietary storage method. This would lead to a fragmented ecosystem where\nusers cannot easily move their accounts between different tools, increasing\nfriction and the risk of key handling errors.\n\nBy defining a single, clear standard, this LIP ensures that a keyset generated\nby one tool (like lea-keygen) can be seamlessly used by any other compliant tool\n(like the ltm builder). This promotes interoperability, simplifies development,\nand improves the overall user experience.\n\n\nSpecification#\n\nA LEA Keyset file is a JSON file containing a single top-level array. The\nstructure is defined as follows:\n\nRoot: A JSON Array with two elements.\n\n * Element 1: Ed25519 Secret Key\n   \n   * Type: Array<number>\n   * Description: An array of 64 integers, where each integer represents a byte\n     of the Ed25519 secret key. The public key is implicitly the last 32 bytes\n     of this secret key.\n\n * Element 2: SPHINCS+ Keyset\n   \n   * Type: Array\n   * Description: A nested array containing the SPHINCS+ secret and public keys.\n     * Element 2.1: SPHINCS+ Secret Key\n       * Type: Array<number>\n       * Description: An array of 64 integers representing the bytes of the\n         SPHINCS+ secret key.\n     * Element 2.2: SPHINCS+ Public Key\n       * Type: Array<number>\n       * Description: An array of 32 integers representing the bytes of the\n         SPHINCS+ public key.\n\n\nJSON Structure Example#\n\n\n\n\nRationale#\n\n * JSON as a Base: JSON is a universally supported, human-readable format,\n   making it an ideal choice for a simple key storage standard.\n * Array of Arrays: This structure was chosen for its compactness and strict\n   ordering. Compared to a JSON object with named keys, it reduces file size and\n   removes ambiguity about property names. The fixed positions of each key make\n   parsing simple and efficient.\n * Array of Integers for Binary Data: Representing raw binary data as an array\n   of byte-sized integers (0-255) is a standard, language-agnostic method that\n   avoids the overhead and complexity of Base64 or hex string encoding within\n   the JSON file itself.\n\n\nBackwards Compatibility#\n\nThis is a new, additive standard. It does not break any existing protocol rules\nor formats and will serve as the standard for all tools created after its\nacceptance.\n\n\nSecurity Considerations#\n\nThis file contains unencrypted private keys and is extremely sensitive.\n\n * File Permissions: Any tool that creates a LEA Keyset file (e.g., lea-keygen)\n   MUST set the file permissions to 0o600 (user-read-write only) to prevent\n   unauthorized access by other users on the same system.\n * Parsing: A compliant parser MUST validate the structure of the file,\n   including the presence and lengths of all arrays, to prevent errors and\n   potential vulnerabilities from malformed keyset files.\n\n\nCopyright#\n\nThis LIP is licensed under the MIT License.","routePath":"/lips/LIP-0012","lang":"","toc":[{"text":"Abstract","id":"abstract","depth":2,"charIndex":134},{"text":"Motivation","id":"motivation","depth":2,"charIndex":527},{"text":"Specification","id":"specification","depth":2,"charIndex":1251},{"text":"JSON Structure Example","id":"json-structure-example","depth":3,"charIndex":2145},{"text":"Rationale","id":"rationale","depth":2,"charIndex":2173},{"text":"Backwards Compatibility","id":"backwards-compatibility","depth":2,"charIndex":2858},{"text":"Security Considerations","id":"security-considerations","depth":2,"charIndex":3052},{"text":"Copyright","id":"copyright","depth":2,"charIndex":3572}],"domain":"","frontmatter":{},"version":""},{"id":18,"title":"LEA Improvement Proposals (LIPs) Index","content":"#\n\nThis table provides an overview and status of the current LIPs for the LEA\nproject.\n\nNUMBER   LAYER           TITLE                                                         OWNER (AUTHOR)     STATUS\n1        Core Encoding   Extend Tag 10 for Sub-Typed Data (IxData Field)               Allwin Ketnawang   Replaced\n2        Core Encoding   Typed Crypto Schemes and Segregated PQC Signature Proofs      Allwin Ketnawang   Replaced\n3        Meta/Process    LIP Structure and Process                                     Allwin Ketnawang   Proposed\n4        Core Encoding   Decouple Legacy Index Field from List Context                 Allwin Ketnawang   Replaced\n5        Core Encoding   Generalize Vectors with Explicit Entry Sizes                  Allwin Ketnawang   Replaced\n6        Core Encoding   Replace Core Transaction Encoding (CTE) with Simple Compact   Allwin Ketnawang   Proposed\n                         Transaction Protocol (SCTP)\n7        Application     Genesis LEA Transaction Decoder Format                        Allwin Ketnawang   Draft\n8        Application     VM's Supported Features                                       Allwin Ketnawang   Draft\n9        Consensus       Programmable Transaction Format                               Allwin Ketnawang   Draft\n10       Application     Transaction Manifest (LTM)                                    Allwin Ketnawang   Proposed\n11       Application     Public Key Module Interface (LEA-PKMI)                        Allwin Ketnawang   Proposed\n12       Application     Keyset File Format                                            Allwin Ketnawang   Proposed","routePath":"/lips/README","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":19,"title":"LEA Improvement Proposals (LIPs) Index","content":"#\n\nThis page provides an overview of the current and active LEA Improvement\nProposals.\n\nNUMBER     TITLE                                                         LAYER           STATUS\nLIP-0003   LIP Structure and Process                                     Meta/Process    Proposed\nLIP-0006   Replace Core Transaction Encoding (CTE) with Simple Compact   Core Encoding   Proposed\n           Transaction Protocol (SCTP)\nLIP-0007   Genesis Transaction Decoder Format                            Application     Draft\nLIP-0008   VM's Supported Features                                       Application     Draft\nLIP-0009   Programmable Transaction Format                               Consensus       Draft\nLIP-0010   Transaction Manifest (LTM)                                    Application     Proposed\nLIP-0011   Public Key Module Interface (LEA-PKMI)                        Application     Proposed\nLIP-0012   Keyset File Format                                            Application     Proposed","routePath":"/lips/","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":20,"title":"LTM Module Usage","content":"ltm#\n\nNode.js module for programmatically building and decoding Lea Chain Transaction\nManifests.\n\n\nLTM Module Usage#\n\nThis guide provides detailed instructions and examples for using the ltm package\nas a Node.js module.\n\n\nInstallation#\n\nInstall the package using npm:\n\n\n\n--------------------------------------------------------------------------------\n\n\nCore Functions#\n\nThe module exports two primary asynchronous functions: build and decode.\n\n\n\n--------------------------------------------------------------------------------\n\n\n1. build(ltmObject)#\n\nProgrammatically constructs and signs a binary transaction from a JavaScript\nobject.\n\n * Parameter: ltmObject (Object) - A JavaScript object that follows the LTM\n   schema. Note: The outputFile field is ignored by this function.\n * Returns: A Promise that resolves to a Uint8Array containing the raw binary\n   transaction data.\n\nImportant Note on Browser Usage#\n\nThe build function has limitations in a browser environment. Specifically, any\nLTM feature that requires file system access or command execution will not work.\nThis includes:\n\n * The signers object (which reads key files).\n * The $file(), $json(), and $exec() placeholders.\n\nIf these features are used in a browser context, the function will throw an\nerror. To build transactions in a browser, you must provide all data, including\nkey material, directly within the ltmObject.\n\nExample: Building a Transaction in Node.js#\n\nThis example demonstrates building a transaction by providing the keyset\ndirectly as a JavaScript array.\n\n\n\n--------------------------------------------------------------------------------\n\n\n2. decode(binaryData)#\n\nDecodes a binary transaction into a human-readable JavaScript object. This\nfunction is universal and works the same in both Node.js and browser\nenvironments.\n\n * Parameter: binaryData (Buffer | Uint8Array) - The binary transaction data to\n   decode.\n * Returns: A Promise that resolves to a JavaScript object representing the\n   transaction.\n\nExample: Decoding a Transaction#\n\nThis example reads a binary transaction file and prints its decoded contents.\n\n\n\n--------------------------------------------------------------------------------","routePath":"/npm-module/generated/ltm","lang":"","toc":[{"text":"Installation","id":"installation","depth":2,"charIndex":221},{"text":"Core Functions","id":"core-functions","depth":2,"charIndex":353},{"text":"1. `build(ltmObject)`","id":"1-buildltmobject","depth":3,"charIndex":-1},{"text":"Important Note on Browser Usage","id":"important-note-on-browser-usage","depth":4,"charIndex":880},{"text":"Example: Building a Transaction in Node.js","id":"example-building-a-transaction-in-nodejs","depth":4,"charIndex":1391},{"text":"2. `decode(binaryData)`","id":"2-decodebinarydata","depth":3,"charIndex":-1},{"text":"Example: Decoding a Transaction","id":"example-decoding-a-transaction","depth":4,"charIndex":1994}],"domain":"","frontmatter":{},"version":""},{"id":21,"title":"NPM Modules","content":"#\n\nThis section provides documentation for the official NPM modules used to\ninteract with the LEA Chain.","routePath":"/npm-module/","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":22,"title":"`lea-keygen` Command-Line Usage","content":"lea-keygen#\n\nA CLI tool for generating and managing Lea Chain keysets.\n\n\nlea-keygen Command-Line Usage#\n\nThis guide provides detailed instructions for using the lea-keygen command-line\ntool to generate Lea Chain keysets.\n\n\nInstallation#\n\nFor one-off commands, you can use npx without any installation:\n\n\n\nAlternatively, you can install it globally to use the lea-keygen command\ndirectly:\n\n\n\n--------------------------------------------------------------------------------\n\n\nCommands#\n\nThe lea-keygen tool supports two main commands: new and verify.\n\n\nnew Command#\n\nGenerates a new keyset.\n\nSynopsis#\n\n\n\nOptions#\n\n * --no-outfile: Prints the generated keyset to standard output (stdout) as a\n   JSON array instead of saving it to a file.\n * --outfile <path>: Specifies a custom file path to save the keyset. If this is\n   not provided, the keyset is saved to <address>.json in the current directory.\n * --force: If a keyset file already exists at the target path, this flag allows\n   overwriting it. Without this flag, the tool will exit with an error to\n   prevent accidental data loss.\n\nExamples#\n\n1. Generate a Keyset and Save to a File#\n\nThis is the default behavior. It generates a new keyset and saves it to a file\nnamed after the derived public address.\n\nCommand:\n\n\n\nOutput (to stderr):\n\n\n\nThe resulting file will contain the full keyset with secure file permissions\n(600).\n\n2. Generate a Keyset and Print to Console#\n\nUse the --no-outfile flag to prevent writing to a file and instead print the\nkeyset to stdout.\n\nCommand:\n\n\n\nOutput (to stdout):\n\n\n\nOutput (to stderr):\n\n\n\n--------------------------------------------------------------------------------\n\n\nverify Command#\n\nDisplays the public address for a given keyset file.\n\nSynopsis#\n\n\n\n * <file_path>: The path to the keyset JSON file.\n\nDescription#\n\nThis command reads a keyset file, derives the public address from it, and prints\nthe address to standard output. This is useful for verifying the address of a\nwallet without needing to generate a new key.\n\nExample#\n\nCommand:\n\n\n\nOutput (to stdout):\n\n\n\n--------------------------------------------------------------------------------","routePath":"/tools/generated/lea-keygen","lang":"","toc":[{"text":"Installation","id":"installation","depth":2,"charIndex":222},{"text":"Commands","id":"commands","depth":2,"charIndex":473},{"text":"`new` Command","id":"new-command","depth":3,"charIndex":-1},{"text":"Synopsis","id":"synopsis","depth":4,"charIndex":589},{"text":"Options","id":"options","depth":4,"charIndex":602},{"text":"Examples","id":"examples","depth":4,"charIndex":1087},{"text":"`verify` Command","id":"verify-command","depth":3,"charIndex":-1},{"text":"Synopsis","id":"synopsis-1","depth":4,"charIndex":1732},{"text":"Description","id":"description","depth":4,"charIndex":1796},{"text":"Example","id":"example","depth":4,"charIndex":2016}],"domain":"","frontmatter":{},"version":""},{"id":23,"title":"LTM Command-Line Usage","content":"ltm#\n\nCommand-line interface for building and decoding Lea Chain Transaction\nManifests.\n\n\nLTM Command-Line Usage#\n\nThis guide provides detailed instructions for using the ltm command-line tool.\n\n\nInstallation#\n\nFor one-off commands, you can use npx without any installation:\n\n\n\nAlternatively, you can install it globally to use the ltm command directly:\n\n\n\n--------------------------------------------------------------------------------\n\n\nCommands#\n\nThe CLI has two main commands: build and decode.\n\n\n1. build#\n\nConstructs and signs a binary transaction from a JSON-based LTM file.\n\nSynopsis#\n\n\n\n * <file_path>: The path to your LTM JSON file.\n\nDescription#\n\nThe build command reads a specified LTM file, resolves all placeholders,\nassembles the transaction, and signs it.\n\nIf the outputFile field is present in the manifest, the binary data is written\nto that file. If outputFile is omitted, the raw binary data is written to\nstandard output (stdout), allowing it to be piped to other tools.\n\nExample 1: Writing to a File#\n\nIf my-transaction.json contains an outputFile field, the output is saved to that\nfile. This example also shows loading signers using placeholders.\n\n\n\nCommand Execution:\n\n\n\nOutput (to stderr):\n\n\n\nExample 2: Piping to Standard Output#\n\nIf stdout-transaction.json omits the outputFile field, the output is piped to\nstdout.\n\n\n\nCommand Execution:\n\n\n\nOutput (to stdout): The raw binary data of the transaction. (The example above\nshows it being piped to the decode command).\n\n--------------------------------------------------------------------------------\n\n\n2. decode#\n\nDecodes a binary transaction into a human-readable JSON format.\n\nSynopsis#\n\n\n\n * <file_path>: The path to the binary transaction file. Use - to read from\n   standard input (stdin).\n\nDescription#\n\nThis command is the reverse of build. It reads a binary transaction from a file\nor standard input and writes the decoded JSON representation to standard output\n(stdout). It is useful for verifying the contents of a binary transaction before\nbroadcasting it.\n\nExample#\n\nCommand Execution:\n\n\n\nOutput (example format):\n\n\n\n--------------------------------------------------------------------------------","routePath":"/tools/generated/ltm","lang":"","toc":[{"text":"Installation","id":"installation","depth":2,"charIndex":195},{"text":"Commands","id":"commands","depth":2,"charIndex":439},{"text":"1. `build`","id":"1-build","depth":3,"charIndex":-1},{"text":"Synopsis","id":"synopsis","depth":4,"charIndex":583},{"text":"Description","id":"description","depth":4,"charIndex":645},{"text":"Example 1: Writing to a File","id":"example-1-writing-to-a-file","depth":4,"charIndex":994},{"text":"Example 2: Piping to Standard Output","id":"example-2-piping-to-standard-output","depth":4,"charIndex":1220},{"text":"2. `decode`","id":"2-decode","depth":3,"charIndex":-1},{"text":"Synopsis","id":"synopsis-1","depth":4,"charIndex":1655},{"text":"Description","id":"description-1","depth":4,"charIndex":1772},{"text":"Example","id":"example","depth":4,"charIndex":2045}],"domain":"","frontmatter":{},"version":""},{"id":24,"title":"Tools","content":"#\n\nThis section provides documentation for the various command-line tools and\nutilities available for the LEA Chain ecosystem.","routePath":"/tools/","lang":"","toc":[],"domain":"","frontmatter":{},"version":""}]